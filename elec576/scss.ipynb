{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Channel Source Separation\n",
    "Tensorflow implementation of convolutional autoencoder in [DeepConvSep](https://github.com/MTG/DeepConvSep) from Chanda et al., 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "Something weird is happening where the GPU is not being recognized in the `elec576` conda env. Just stick with the `vizdoom` env for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If using one or multiple GPUs\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os, errno\n",
    "import re\n",
    "from time import time, sleep\n",
    "#from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_directory(f):\n",
    "    \"\"\"Makes directory if does not already exist\"\"\"\n",
    "    try:\n",
    "        os.makedirs(f)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer definitions\n",
    "I was confused about the decoding portion of the network but read up on docs for clarification. According to the Lasagne docs:\n",
    "\n",
    "---\n",
    "The `InverseLayer` class performs inverse operations for a single layer of a neural network by applying the partial derivative of the layer to be inverted with respect to its input: transposed layer for a `DenseLayer`, deconvolutional layer for `Conv2DLayer`, `Conv1DLayer`; or an unpooling layer for `MaxPool2DLayer`.\n",
    "\n",
    "It is specially useful for building (convolutional) autoencoders with tied parameters.\n",
    "\n",
    "Note that if the layer to be inverted contains a nonlinearity and/or a bias, the InverseLayer will include the derivative of that in its computation.\n",
    "\n",
    "---\n",
    "For convolutional networks, applying the derivative of the layer with respect to its input (e.g. dCONV/dX) amounts to multiplying by the tranpose of its weight matrix (assuming no activation functions in between). That is why, for convolutional layers, `conv2d_transpose` (using the same weights) and `inverse layer` are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _check_list(arg):\n",
    "    if isinstance(arg, list):\n",
    "        try:\n",
    "            return arg[0], arg[1:]\n",
    "        except IndexError:\n",
    "            return arg[0], []\n",
    "    else:\n",
    "        return arg, []\n",
    "\n",
    "def _get_variable_initializer(init_type, var_shape, *args):\n",
    "    if init_type == \"random_normal\":\n",
    "        mean = float(args[0])\n",
    "        stddev = float(args[1])\n",
    "        return tf.random_normal(var_shape, mean=mean, stddev=stddev)\n",
    "    elif init_type == \"truncated_normal\":\n",
    "        mean = float(args[0])\n",
    "        stddev = float(args[1])\n",
    "        return tf.truncated_normal(var_shape, mean=mean, stddev=stddev)\n",
    "    elif init_type == \"constant\":\n",
    "        c = args[0]\n",
    "        return tf.constant(c, dtype=tf.float32, shape=var_shape)\n",
    "    elif init_type == \"xavier\":\n",
    "        n_in = tf.cast(args[0], tf.float32)\n",
    "        return tf.div(tf.random_normal(var_shape), tf.sqrt(n_in))\n",
    "    else:\n",
    "        raise ValueError(\"Variable initializer \\\"\" + init_type + \"\\\" not supported.\")\n",
    "\n",
    "def _apply_normalization(norm_type, x, *args, **kwargs):\n",
    "    if norm_type == \"batch_norm\":\n",
    "        return batch_norm(x, *args, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Normalization type \\\"\" + norm_type + \"\\\" not supported.\")\n",
    "\n",
    "def _apply_activation(activation_type, x, *args):\n",
    "    if activation_type.lower() == \"relu\":\n",
    "        return tf.nn.relu(x, name=\"Relu\")\n",
    "    elif activation_type.lower() == \"leaky_relu\":\n",
    "        return tf.maximum(x, 0.1 * x, name=\"Leaky_Relu\")\n",
    "    elif activation_type.lower() == \"softmax\":\n",
    "        return tf.nn.softmax(x)\n",
    "    elif activation_type.lower() == \"none\":\n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError(\"Activation type \\\"\" + activation_type + \"\\\" not supported.\")\n",
    "        \n",
    "def conv2d(input_layer,\n",
    "           num_outputs,\n",
    "           kernel_size,\n",
    "           stride=1,\n",
    "           padding=\"VALID\",\n",
    "           data_format=\"NCHW\",\n",
    "           normalizer_fn=None,\n",
    "           activation_fn=None,\n",
    "           weights_initializer=\"random_normal\",\n",
    "           biases_initializer=None,\n",
    "           trainable=True,\n",
    "           scope=\"CONV\"):\n",
    "    with tf.name_scope(scope):\n",
    "        input_shape = input_layer.get_shape().as_list()\n",
    "        \n",
    "        # Create weights\n",
    "        W_init_type, W_init_params = _check_list(weights_initializer)\n",
    "        with tf.name_scope(W_init_type + \"_initializer\"):\n",
    "            if data_format == \"NHWC\":\n",
    "                input_channels = input_shape[3]\n",
    "            elif data_format == \"NCHW\":\n",
    "                input_channels = input_shape[1]\n",
    "            W_shape = kernel_size + [input_channels, num_outputs]\n",
    "            if W_init_type == \"xavier\":\n",
    "                layer_shape = input_shape[1:]\n",
    "                n_in = tf.reduce_prod(layer_shape)\n",
    "                W_init_params = [n_in] \n",
    "            W_init = _get_variable_initializer(W_init_type,\n",
    "                                                W_shape,\n",
    "                                                *W_init_params)\n",
    "        W = tf.Variable(W_init, \n",
    "                        dtype=tf.float32, \n",
    "                        trainable=trainable, \n",
    "                        name=\"weights\")\n",
    "        \n",
    "\n",
    "        # Convolute input\n",
    "        stride_h, stride_w = _check_list(stride)\n",
    "        if isinstance(stride_w, list):\n",
    "            if len(stride_w) == 0:\n",
    "                stride_w = stride_h\n",
    "            else:\n",
    "                stride_w = stride_w[0]\n",
    "        if data_format == \"NHWC\":\n",
    "            strides = [1, stride_h, stride_w, 1]\n",
    "        elif data_format == \"NCHW\":\n",
    "            strides = [1, 1, stride_h, stride_w]\n",
    "        out = tf.nn.conv2d(input_layer, \n",
    "                            filter=W,\n",
    "                            strides=strides,\n",
    "                            padding=padding,\n",
    "                            data_format=data_format,\n",
    "                            name=\"convolution\")\n",
    "        \n",
    "        # Apply normalization\n",
    "        if normalizer_fn is not None:\n",
    "            norm_type, norm_params = _check_list(normalizer_fn)\n",
    "            out = _apply_normalization(norm_type, \n",
    "                                       out, \n",
    "                                       *norm_params,\n",
    "                                       data_format=data_format)\n",
    "        \n",
    "        # Add biases\n",
    "        elif biases_initializer is not None:\n",
    "            b_init_type, b_init_params = _check_list(biases_initializer)\n",
    "            if data_format == \"NHWC\":\n",
    "                b_shape = [1, 1, 1, num_outputs]\n",
    "            elif data_format == \"NCHW\":\n",
    "                b_shape = [1, num_outputs, 1, 1]\n",
    "            b_init = _get_variable_initializer(b_init_type,\n",
    "                                               b_shape,\n",
    "                                               *b_init_params)\n",
    "            b = tf.Variable(b_init,\n",
    "                            dtype=tf.float32,\n",
    "                            trainable=trainable,\n",
    "                            name=\"biases\")\n",
    "            out = tf.add(out, b, name=\"BiasAdd\")\n",
    "\n",
    "        # Apply activation\n",
    "        if activation_fn is not None:\n",
    "            act_type, act_params = _check_list(activation_fn)\n",
    "            out = _apply_activation(act_type, out, *act_params)\n",
    "\n",
    "        return out\n",
    "\n",
    "def inverse_conv2d(x,\n",
    "                   output_shape,\n",
    "                   conv_weights,\n",
    "                   conv_stride, \n",
    "                   padding=\"VALID\",\n",
    "                   data_format=\"NCHW\",\n",
    "                   scope=\"CONV_T\"):\n",
    "    with tf.name_scope(scope):\n",
    "        # Get input shape\n",
    "        x_shape = x.get_shape().as_list()\n",
    "        \n",
    "        # Ignore subtracting shared biases or adding new ones\n",
    "        \n",
    "        # Get shared weights from conv layer to be inverted\n",
    "        # Change shape from [k_w, k_h, in_ch, out_ch] to [k_w, k_h, out_ch, in_ch]\n",
    "        W = conv_weights\n",
    "        #W = tf.transpose(conv_weights, perm=[0, 1, 3, 2])\n",
    "\n",
    "        # Set stride\n",
    "        stride_h, stride_w = _check_list(conv_stride)\n",
    "        if isinstance(stride_w, list):\n",
    "            if len(stride_w) == 0:\n",
    "                stride_w = stride_h\n",
    "            else:\n",
    "                stride_w = stride_w[0]\n",
    "        if data_format == \"NHWC\":\n",
    "            strides = [1, stride_h, stride_w, 1]\n",
    "        elif data_format == \"NCHW\":\n",
    "            strides = [1, 1, stride_h, stride_w]\n",
    "            \n",
    "        # Perform convolutional transpose\n",
    "        out = tf.nn.conv2d_transpose(x, \n",
    "                                     filter=W,\n",
    "                                     output_shape=output_shape,\n",
    "                                     strides=strides,\n",
    "                                     padding=padding,\n",
    "                                     data_format=data_format,\n",
    "                                     name=\"convolution_transpose\")\n",
    "        \n",
    "        return out\n",
    "    \n",
    "def flatten(input_layer, \n",
    "            data_format=\"NCHW\",\n",
    "            scope=\"FLAT\"):\n",
    "    with tf.name_scope(scope):\n",
    "        # Grab runtime values to determine number of elements\n",
    "        input_shape = tf.shape(input_layer)\n",
    "        input_ndims = input_layer.get_shape().ndims\n",
    "        batch_size = tf.slice(input_shape, [0], [1])\n",
    "        layer_shape = tf.slice(input_shape, [1], [input_ndims-1])\n",
    "        num_neurons = tf.expand_dims(tf.reduce_prod(layer_shape), 0)\n",
    "        flattened_shape = tf.concat([batch_size, num_neurons], 0)\n",
    "        if data_format == \"NHWC\":\n",
    "            input_layer = tf.transpose(input_layer, perm=[0, 3, 1, 2])\n",
    "        flat = tf.reshape(input_layer, flattened_shape)\n",
    "        \n",
    "        # Attempt to set values during graph building\n",
    "        input_shape = input_layer.get_shape().as_list()\n",
    "        batch_size, layer_shape = input_shape[0], input_shape[1:]\n",
    "        if all(layer_shape): # None not present\n",
    "            num_neurons = 1\n",
    "            for dim in layer_shape:\n",
    "                num_neurons *= dim\n",
    "            flat.set_shape([batch_size, num_neurons])\n",
    "        else: # None present\n",
    "            flat.set_shape([batch_size, None])\n",
    "        return flat\n",
    "\n",
    "def fully_connected(input_layer,\n",
    "                    num_outputs,\n",
    "                    normalizer_fn=None,\n",
    "                    activation_fn=None,\n",
    "                    weights_initializer=\"random_normal\",\n",
    "                    biases_initializer=None,\n",
    "                    trainable=True,\n",
    "                    scope=\"FC\"):\n",
    "    with tf.name_scope(scope):\n",
    "        input_shape = input_layer.get_shape().as_list()\n",
    "        \n",
    "        # Create weights\n",
    "        W_init_type, W_init_params = _check_list(weights_initializer)\n",
    "        with tf.name_scope(W_init_type + \"_initializer\"):\n",
    "            W_shape = [input_shape[1], num_outputs]\n",
    "            if W_init_type == \"xavier\":\n",
    "                layer_shape = input_shape[1]\n",
    "                n_in = tf.reduce_prod(layer_shape)\n",
    "                W_init_params = [n_in]\n",
    "            W_init = _get_variable_initializer(W_init_type,\n",
    "                                            W_shape,\n",
    "                                            *W_init_params)\n",
    "        W = tf.Variable(W_init,\n",
    "                        dtype=tf.float32, \n",
    "                        trainable=trainable, \n",
    "                        name=\"weights\")\n",
    "        \n",
    "        # Multiply inputs by weights\n",
    "        out = tf.matmul(input_layer, W)\n",
    "\n",
    "        # Apply normalization\n",
    "        if normalizer_fn is not None:\n",
    "            norm_type, norm_params = _check_list(normalizer_fn)\n",
    "            out = _apply_normalization(norm_type, \n",
    "                                       out, \n",
    "                                       *norm_params,\n",
    "                                       data_format=None)\n",
    "\n",
    "        # Add biases\n",
    "        elif biases_initializer is not None:\n",
    "            b_init_type, b_init_params = _check_list(biases_initializer)\n",
    "            b_shape = [num_outputs]\n",
    "            b_init = _get_variable_initializer(b_init_type,\n",
    "                                               b_shape,\n",
    "                                               *b_init_params)\n",
    "            b = tf.Variable(b_init,\n",
    "                            dtype=tf.float32,\n",
    "                            trainable=trainable,\n",
    "                            name=\"biases\")\n",
    "            out = tf.add(out, b, name=\"BiasAdd\")\n",
    "       \n",
    "        # Apply activation\n",
    "        if activation_fn is not None:\n",
    "            act_type, act_params = _check_list(activation_fn)\n",
    "            out = _apply_activation(act_type, out, *act_params)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataset handling\n",
    "The training data will be fed in a given amount of files at a time specified by number of mixture-source feature file pairs.\n",
    "There are two approaches to using mem map, and unfortunately neither seems to completely avoid moving large amounts of data upon initialization:\n",
    "1. Use `np.memmap` following instructions from [this stackoverflow question](https://stackoverflow.com/questions/13780907/is-it-possible-to-np-concatenate-memory-mapped-files). The third (placeholder) array ends up writing all data to the file of the initial array. This in essence creates a single, giant array that contains the concatenated information from all songs along the time axis. While this would work, it doubles the amount of space on the hard drive if not deleted after training, and takes a long time (~30 min) to initialize if deleted after every use.\n",
    "2. Use the `mmap_mode` arg in `np.load`. While this works for single files, any results of manipulation of the arrays (e.g. `np.concatenate` along time axis) are loaded into memory, which defeats the purpose of using mmap in the first place.\n",
    "\n",
    "I think the best compromise is to use `np.load(filename, mmap_mode='r')` to point to the arrays and grab shapes initially, which can be used to track the global time point. Then some number of files can be loaded at a time that correspond to the number of time points to load at a time. Class variables can track the global time point, time point within loaded files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 load_by_file=False,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal'],\n",
    "                 data_format=\"NHWC\",\n",
    "                 shuffle=True,\n",
    "                 scale_factor=1.0,\n",
    "                 verbose=True):\n",
    "        # Grab arguments\n",
    "        self.batch_size = batch_size\n",
    "        self.time_context = time_context\n",
    "        self.num_sources = len(sources)\n",
    "        self.data_format = data_format\n",
    "        self.shuffle = shuffle\n",
    "        self.verbose = verbose\n",
    "        self.load_by_file = load_by_file\n",
    "        \n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) \n",
    "                                   for f in os.listdir(input_dir) if \"mag\" in f])\n",
    "        target_files = sorted([os.path.join(target_dir, f) \n",
    "                               for f in os.listdir(target_dir) if \"mag\" in f])\n",
    "        self.source_files = [] # [source_id][t]\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "        \n",
    "        # Read mem maps of data files\n",
    "        self.inputs = []\n",
    "        self.sources = [] # [t][source_id]\n",
    "        self.shapes = []\n",
    "        shapes_ = [] # placeholder to ensure all associated shapes equal\n",
    "        for i in range(len(self.input_files)):\n",
    "            if verbose:\n",
    "                end = '\\n' if i == len(self.input_files)-1 else '\\r'\n",
    "                print(\"Reading file %d of %d\" % (i+1, len(self.input_files)), end=end)\n",
    "            \n",
    "            # Add mem map of mixture file\n",
    "            f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            self.inputs.append(f_in)\n",
    "            \n",
    "            # Add mem maps of source files\n",
    "            f_s = [np.load(self.source_files[j][i], mmap_mode='r') \n",
    "                   for j in range(len(sources))]\n",
    "            self.sources.append(f_s)\n",
    "            \n",
    "            # Get shapes\n",
    "            self.shapes.append(f_in.shape)\n",
    "            shapes_.append([f.shape for f in f_s])\n",
    "        \n",
    "        # Set class variables\n",
    "        self.shapes = np.asarray(self.shapes)\n",
    "        self.t_total = np.sum(self.shapes[:, 0])\n",
    "        self.feat_size = self.shapes[0, 1]\n",
    "        \n",
    "        # Check that shapes [index, ch, shape] are equal for each time point\n",
    "        shapes_ = np.concatenate([self.shapes[:, np.newaxis, :], np.asarray(shapes_)], axis=1)\n",
    "        if not (shapes_[:, :, 0].T == shapes_[:, 0, 0]).all():\n",
    "            raise ValueError(\"All spectrograms must be of same length.\")\n",
    "        if not (shapes_[:, :, 1].T == shapes_[:, 0, 1]).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        shapes_ = None # release from memory\n",
    "            \n",
    "        # Set variables to track time position\n",
    "        self.t_c = np.cumsum(self.shapes[:, 0])\n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_next = False # if True, load next batch of files\n",
    "        self.inputs_, self.sources_ = [], []\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        # Get indices of files corresponding to next mem_len time points or next file\n",
    "        t_start = self.t\n",
    "        t_end = self.t + self.mem_len\n",
    "        idx_start = np.searchsorted(self.t_c, t_start, side='right')\n",
    "        if self.load_by_file:\n",
    "            idx_end = idx_start + 1\n",
    "        else:\n",
    "            idx_end = np.searchsorted(self.t_c, t_end, side='right')\n",
    "        if idx_end - idx_start < 1:\n",
    "            raise SyntaxError(\"Unable to load next file. Check mem_len (must be greater than file size)\")\n",
    "        if self.verbose:\n",
    "            print(\"Loading files %d to %d of %d into memory...\" % (idx_start+1, idx_end, len(self.inputs)))\n",
    "        \n",
    "        # Clear memory\n",
    "        del self.sources_\n",
    "        del self.inputs_\n",
    "        \n",
    "        # Load from mem maps of files into shape [time, features, [num_sources]]:\n",
    "        # from inputs\n",
    "        f_in = [self.inputs[t] for t in range(idx_start, idx_end)] # get list of next files\n",
    "        #self.inputs_ = np.concatenate(f_in, axis=0) # loads into memory but SLOW\n",
    "        t_shape = np.sum(self.shapes[idx_start:idx_end, 0]) # grab total shape ahead of time (much faster)\n",
    "        self.inputs_ = np.zeros([t_shape, self.feat_size]) # set total memory block\n",
    "        t_idx = 0 # running time index\n",
    "        for i, f in enumerate(f_in):\n",
    "            self.inputs_[t_idx:t_idx+self.shapes[idx_start+i, 0]] = f\n",
    "            t_idx += self.shapes[idx_start+i, 0]\n",
    "        \n",
    "        # from sources\n",
    "        f_s = [np.asarray(self.sources[t]) for t in range(idx_start, idx_end)]\n",
    "        #self.sources_ = np.transpose(np.concatenate(f_s, axis=1), axes=[1, 2, 0]) # loads into memory\n",
    "        self.sources_ = np.zeros([t_shape, self.feat_size, self.num_sources])\n",
    "        t_idx = 0\n",
    "        for i, f in enumerate(f_s):\n",
    "            self.sources_[t_idx:t_idx+self.shapes[idx_start+i, 0]] = np.transpose(f, [1, 2, 0])\n",
    "            t_idx += self.shapes[idx_start+i, 0]\n",
    "        \n",
    "        # Scale if specified\n",
    "        self.inputs_ *= scale_factor\n",
    "        self.sources_ *= scale_factor\n",
    "        \n",
    "        # Shuffle chunks of size time context\n",
    "        if self.shuffle:\n",
    "            self.shuffle_data()\n",
    "        \n",
    "        # Reset counter\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def shuffle_data(self):\n",
    "        # This increases memory requirements by ~50% (copying self.inputs_ or self.sources_ \n",
    "        # during reshape operations. I don't know of a way to reshape in place without \n",
    "        # copying the array, which is affirmed in the numpy docs.\n",
    "        if self.verbose:\n",
    "            print(\"Shuffling data...\")\n",
    "        \n",
    "        # Reshape data into chunks of size time_context and save ends\n",
    "        concat = False\n",
    "        if self.inputs_.shape[0] % self.time_context != 0:\n",
    "            end_idx = self.inputs_.shape[0] // self.time_context * self.time_context\n",
    "            end_inputs = self.inputs_[end_idx:]\n",
    "            self.inputs_ = self.inputs_[:end_idx]\n",
    "            end_sources = self.sources_[end_idx:]\n",
    "            self.sources_ = self.sources_[:end_idx]\n",
    "            concat = True\n",
    "        self.inputs_ = self.inputs_.reshape([-1, self.time_context, self.feat_size])\n",
    "        self.sources_ = self.sources_.reshape([-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        \n",
    "        # Shuffle inputs and sources in unison\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(self.inputs_)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(self.sources_)\n",
    "        \n",
    "        # Reshape data into original shape [time, features, [num_sources]]\n",
    "        self.inputs_ = self.inputs_.reshape([-1, self.feat_size])\n",
    "        self.sources_ = self.sources_.reshape([-1, self.feat_size, self.num_sources])\n",
    "        if concat:\n",
    "            self.inputs_ = np.concatenate([self.inputs_, end_inputs])\n",
    "            self.sources_ = np.concatenate([self.sources_, end_sources])\n",
    "    \n",
    "    def reset_database(self):\n",
    "        if self.verbose:\n",
    "            print(\"Resetting database...\")\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Load memory if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        elif self.load_next:\n",
    "            self.load_memory()\n",
    "        \n",
    "        # Determine batch length and set loading bools for next batch\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        rem = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        if self.t + batch_len > self.t_total: # reach end of all data\n",
    "            batch_len = (self.t_total - self.t) // self.time_context * self.time_context\n",
    "            rem = (self.t_total - self.t) % self.time_context\n",
    "            self.reset = True\n",
    "        elif self.t_ + batch_len > self.inputs_.shape[0]: # reach end of loaded data\n",
    "            batch_len = (self.inputs_.shape[0] - self.t_) // self.time_context * self.time_context\n",
    "            rem = (self.inputs_.shape[0] - self.t_) % self.time_context\n",
    "            self.load_next = True\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[self.t_:self.t_+batch_len],\n",
    "                                  [-1, self.time_context, self.feat_size, 1])\n",
    "        sources_batch = np.reshape(self.sources_[self.t_:self.t_+batch_len],\n",
    "                                    [-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        if self.data_format == \"NCHW\":\n",
    "            inputs_batch = np.transpose(inputs_batch, axes=[0, 3, 1, 2])\n",
    "            sources_batch = np.transpose(sources_batch, axes=[0, 3, 1, 2])\n",
    "        \n",
    "        # Increment counters\n",
    "        self.t_ += batch_len + rem \n",
    "        self.t  += batch_len + rem\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return ds.reset\n",
    "    \n",
    "    def remaining_batches(self):\n",
    "        return math.ceil((self.inputs_.shape[0] - self.t_) \n",
    "                         / (self.batch_size * self.time_context))\n",
    "    \n",
    "    def remaining_files(self):\n",
    "        return len(self.inputs) - np.searchsorted(self.t_c, self.t, side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph building\n",
    "For comparison, check out [this example](https://github.com/pkmital/tensorflow_tutorials/blob/master/python/09_convolutional_autoencoder.py) on github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 results_dir,\n",
    "                 params_file=None,\n",
    "                 data_format=\"NCHW\",\n",
    "                 time_context=30,\n",
    "                 feat_size=513,\n",
    "                 num_sources=4,\n",
    "                 alpha=0.001,\n",
    "                 mean_loss=True,\n",
    "                 verbose=True,\n",
    "                 train_mode=True,\n",
    "                 scope=\"\"):\n",
    "        # Get args\n",
    "        self.results_dir = results_dir\n",
    "        self.data_format = data_format\n",
    "        self.time_context = time_context\n",
    "        self.feat_size = feat_size\n",
    "        self.num_sources = num_sources\n",
    "        self.alpha = alpha\n",
    "        self.scope = scope\n",
    "        self.verbose = verbose\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        # Build graph\n",
    "        tf.reset_default_graph()\n",
    "        with tf.name_scope(scope):\n",
    "            self.build_graph(mean_loss)\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        if params_file is not None:\n",
    "            self.load_model(params_file)\n",
    "        \n",
    "        self.global_step = 0\n",
    "        \n",
    "\n",
    "    def build_graph(self, mean_loss):\n",
    "        eps = 1e-18 # numerical stability\n",
    "        self.graph = tf.get_default_graph()\n",
    "        \n",
    "        # Data formatting\n",
    "        if self.verbose:\n",
    "            print(\"Building input...\")\n",
    "        if self.data_format == \"NHWC\":\n",
    "            input_shape = [None, self.time_context, self.feat_size, 1]\n",
    "            target_shape = [None, self.time_context, self.feat_size, self.num_sources]\n",
    "            channel_dim = 3\n",
    "        elif self.data_format == \"NCHW\":\n",
    "            input_shape = [None, 1, self.time_context, self.feat_size]\n",
    "            target_shape = [None, self.num_sources, self.time_context, self.feat_size]\n",
    "            channel_dim = 1\n",
    "        else:\n",
    "            raise ValueError(\"Unknown data format \\\"\" + self.data_format + \"\\\"\")\n",
    "        self.spectrogram = tf.placeholder(tf.float32, \n",
    "                                     shape=input_shape, \n",
    "                                     name=\"magnitude_spectrogram\")\n",
    "        \n",
    "        # Encoder\n",
    "        if self.verbose:\n",
    "            print(\"Building encoder...\")\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = conv2d(self.spectrogram,\n",
    "                       num_outputs=30,\n",
    "                       kernel_size=[1, 30],\n",
    "                       stride=[1, 4],\n",
    "                       padding=\"VALID\",\n",
    "                       data_format=self.data_format,\n",
    "                       weights_initializer=\"xavier\",\n",
    "                       biases_initializer=[\"constant\", 0.0],\n",
    "                       scope=\"CONV_1\")\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = conv2d(self.conv1,\n",
    "                       num_outputs=30,\n",
    "                       kernel_size=[int(2*self.time_context/3), 1],\n",
    "                       stride=[1, 1],\n",
    "                       padding=\"VALID\",\n",
    "                       data_format=self.data_format,\n",
    "                       weights_initializer=\"xavier\",\n",
    "                       biases_initializer=[\"constant\", 0.0],\n",
    "                       scope=\"CONV_2\")\n",
    "        self.conv2_flat = flatten(self.conv2,\n",
    "                             data_format=self.data_format,\n",
    "                             scope=\"CONV_2_FLAT\")\n",
    "\n",
    "        # Fully-connected layer 1 (encoding)\n",
    "        self.fc1 = fully_connected(self.conv2_flat,\n",
    "                              num_outputs=256,\n",
    "                              activation_fn=\"relu\",\n",
    "                              weights_initializer=\"xavier\",\n",
    "                              biases_initializer=[\"constant\", 0.0],\n",
    "                              scope=\"FC_1\")\n",
    "        # Decoder\n",
    "        if self.verbose:\n",
    "            print(\"Building decoder...\")\n",
    "            \n",
    "        # Get shapes and variables for building decoding layers\n",
    "        # Kinda hacky but don't feel like redoing layer definitions right now\n",
    "        batch_size = tf.shape(self.spectrogram)[0]\n",
    "        if len(self.scope) > 0: scope = self.scope + '/'\n",
    "        else:                   scope = self.scope\n",
    "        conv1_shape = self.conv1.get_shape().as_list()\n",
    "        conv1_weights = self.graph.get_tensor_by_name(scope + \"CONV_1/weights:0\")\n",
    "        conv1_biases = self.graph.get_tensor_by_name(scope + \"CONV_1/biases:0\")\n",
    "        conv2_shape = self.conv2.get_shape().as_list()\n",
    "        conv2_size = conv2_shape[1] * conv2_shape[2] * conv2_shape[3]\n",
    "        conv2_weights = self.graph.get_tensor_by_name(scope + \"CONV_2/weights:0\")\n",
    "        conv2_biases = self.graph.get_tensor_by_name(scope + \"CONV_2/biases:0\")\n",
    "\n",
    "        # Build decoder for each source\n",
    "        self.fc2, self.convt1, self.convt2 = [], [], []\n",
    "        for i in range(self.num_sources):\n",
    "            # Fully-connected layer 2 (decoding)\n",
    "            fc2_i = fully_connected(self.fc1,\n",
    "                                    num_outputs=conv2_size,\n",
    "                                    activation_fn=\"relu\",\n",
    "                                    weights_initializer=\"xavier\",\n",
    "                                    biases_initializer=[\"constant\", 0.0],\n",
    "                                    scope=\"FC_2_%d\" % (i+1))\n",
    "            self.fc2.append(fc2_i)\n",
    "\n",
    "            # Convolutional transpose layer 1\n",
    "            # Side note: tf.reshape() can infer size of one dimension given rest, so -1 okay\n",
    "            #            tf.nn.conv2d_transpose() must know exact dimensions, but batch size can\n",
    "            #            be inferred at runtime using tf.shape()\n",
    "            fc2_i = tf.reshape(fc2_i, [-1] + conv2_shape[1:])\n",
    "            convt1_i = inverse_conv2d(fc2_i,\n",
    "                                      output_shape=[batch_size] + conv1_shape[1:],\n",
    "                                      conv_weights=conv2_weights,\n",
    "                                      conv_stride=[1, 1],\n",
    "                                      padding=\"VALID\",\n",
    "                                      data_format=self.data_format,\n",
    "                                      scope=\"CONVT_1_%d\" % (i+1))\n",
    "            self.convt1.append(convt1_i)\n",
    "\n",
    "            # Convolutional transpose layer 2\n",
    "            convt2_i = inverse_conv2d(convt1_i,\n",
    "                                        output_shape=[batch_size] + input_shape[1:],\n",
    "                                        conv_weights=conv1_weights,\n",
    "                                        conv_stride=[1, 4],\n",
    "                                        padding=\"VALID\",\n",
    "                                        data_format=self.data_format,\n",
    "                                        scope=\"CONVT_2_%d\" % (i+1))\n",
    "            self.convt2.append(convt2_i)\n",
    "        \n",
    "        # Output\n",
    "        if self.verbose:\n",
    "            print(\"Building output...\")\n",
    "            \n",
    "        # Output layer\n",
    "        with tf.name_scope(\"y_hat\"):\n",
    "            convt2_all = tf.concat(self.convt2, axis=channel_dim)\n",
    "            b_shape = [1, 1, 1, 1]\n",
    "            b_shape[channel_dim] = self.num_sources\n",
    "            b = tf.Variable(tf.constant(0.0, shape=b_shape),\n",
    "                            dtype=tf.float32,\n",
    "                            name=\"bias\")\n",
    "            self.y_hat = tf.maximum(tf.add(convt2_all, b), 0, name=\"y_hat\")\n",
    "\n",
    "        # Masks: m_n(f) = |y_hat_n(f)| / Σ(|y_hat_n'(f)|)\n",
    "        with tf.name_scope(\"masks\"):\n",
    "            rand = tf.random_uniform([batch_size] + input_shape[1:])\n",
    "            den = tf.reduce_sum(self.y_hat, axis=channel_dim, keep_dims=True) + (eps * rand)\n",
    "            self.masks = tf.div(self.y_hat, den, name=\"masks\") # broadcast along channel dimension\n",
    "\n",
    "        # Source signals: y_tilde_n(f) = m_n(f) * x(f), \n",
    "        # where x(f) is the spectrogram of the input mixture signal\n",
    "        with tf.name_scope(\"y_tilde\"):\n",
    "            self.y_tilde = tf.multiply(self.masks, self.spectrogram, name=\"y_tilde\") # broadcast along channel dimension\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Building losses and summaries...\")\n",
    "            \n",
    "        # Loss function: L = 1/N * Σ(||y_tilde_n - target_n||^2)\n",
    "        # Changed from total to mean loss to account for different feature sizes\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.targets = tf.placeholder(tf.float32, \n",
    "                                     shape=target_shape, \n",
    "                                     name=\"target_sources\")\n",
    "            reduc_indices = [i for i in range(4) if i != channel_dim]\n",
    "            if mean_loss:\n",
    "                loss_fn = tf.reduce_mean\n",
    "            else:\n",
    "                loss_fn = tf.reduce_sum\n",
    "            self.loss_n = loss_fn(tf.square(self.y_tilde - self.targets), \n",
    "                                        axis=reduc_indices, \n",
    "                                        name=\"loss_n\")\n",
    "            self.loss_total = loss_fn(self.loss_n, name=\"loss_total\")\n",
    "        \n",
    "        # Optimizer\n",
    "        with tf.name_scope(\"train_step\"):\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.alpha)\n",
    "            self.train_step = self.optimizer.minimize(self.loss_total)\n",
    "\n",
    "        # Summaries\n",
    "        self.saver = tf.train.Saver(max_to_keep=1)        \n",
    "        self.writer = tf.summary.FileWriter(self.results_dir, self.graph)\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            # Loss summaries\n",
    "            loss_sum = []\n",
    "            with tf.name_scope(\"losses\"):\n",
    "                for i in range(self.num_sources):\n",
    "                    loss_sum.append(tf.summary.scalar(\"loss_%d\" % (i+1), self.loss_n[i]))\n",
    "                loss_sum.append(tf.summary.scalar(\"loss_total\", self.loss_total))\n",
    "                self.loss_sum = tf.summary.merge(loss_sum)\n",
    "            \n",
    "            # Variable summaries\n",
    "            var_sum = []\n",
    "            with tf.name_scope(\"trainable_variables\"):\n",
    "                for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "                    with tf.name_scope(var.name[:-2]):\n",
    "                        mean = tf.reduce_mean(var)\n",
    "                        var_sum.append(tf.summary.scalar(\"mean\", mean))\n",
    "                        with tf.name_scope(\"stddev\"):\n",
    "                            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "                        var_sum.append(tf.summary.scalar(\"stddev\", stddev))\n",
    "                        var_sum.append(tf.summary.scalar(\"max\", tf.reduce_max(var)))\n",
    "                        var_sum.append(tf.summary.scalar(\"min\", tf.reduce_min(var)))\n",
    "                        var_sum.append(tf.summary.histogram(\"histogram\", var))\n",
    "                self.var_sum = tf.summary.merge(var_sum)\n",
    "    \n",
    "    def perform_training_step(self, x, y):\n",
    "        feed_dict = {self.spectrogram: x, self.targets: y}\n",
    "        loss_, _ = self.sess.run([self.loss_total, self.train_step], \n",
    "                                 feed_dict=feed_dict)\n",
    "        self.global_step += 1\n",
    "        return loss_\n",
    "    \n",
    "    def predict(self, x, y=None):\n",
    "        if y is None:\n",
    "            feed_dict = {self.spectrogram: x}\n",
    "            y_tilde_, = self.sess.run(self.y_tilde,\n",
    "                                      feed_dict=feed_dict)\n",
    "            return y_tilde_\n",
    "        else:\n",
    "            feed_dict = {self.spectrogram: x, self.targets: y}\n",
    "            y_tilde_, loss_, = self.sess.run([self.y_tilde, self.loss_total], \n",
    "                                             feed_dict=feed_dict)\n",
    "            return y_tilde_, loss_ \n",
    "    \n",
    "    def save_summaries(self, x, y):\n",
    "        feed_dict = {self.spectrogram: x, self.targets: y}\n",
    "        loss_sum_, var_sum_ = self.sess.run([self.loss_sum, self.var_sum], \n",
    "                                            feed_dict=feed_dict)\n",
    "        self.writer.add_summary(loss_sum_, global_step=self.global_step)\n",
    "        self.writer.add_summary(var_sum_, global_step=self.global_step)\n",
    "        self.writer.flush()\n",
    "    \n",
    "    def save_model(self, epoch, save_meta=True):\n",
    "        self.saver.save(self.sess, self.results_dir + \"model\", \n",
    "                        global_step=epoch, write_meta_graph=save_meta)\n",
    "    \n",
    "    def load_model(self, params_file):\n",
    "        self.saver.restore(self.sess, params_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The initial training in trial 1 on a song from the Bach10 dataset worked very well. That network only took in mag specs with 513 features, as opposed to 1025 with our current DSD100 specs. Further, trying to build graphs for the full 2049 features in the original Bach10 specs causes memory errors. Maybe it is simply too many parameters to learn for stable training. Try downsizing specs to 513 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_train_details(folder, desc):\n",
    "    f = open(folder + \"settings.txt\", \"w+\")\n",
    "    f.write(\"Description: \" + desc + \"\\n\")\n",
    "    f.write(\"Input: \" + input_dir + \"\\n\")\n",
    "    f.write(\"Output: \" + target_dir + \"\\n\")\n",
    "    f.write(\"Epochs: \" + str(num_epochs) + \"\\n\")\n",
    "    f.write(\"Learning rate: \" + str(learning_rate) + \"\\n\")\n",
    "    f.write(\"Loss type: \" + (\"mean\" if mean_loss else \"sum\") + \"\\n\")\n",
    "    f.write(\"Batch size: \" + str(batch_size) + \"\\n\")\n",
    "    f.write(\"Time context: \" + str(time_context) + \"\\n\")\n",
    "    f.write(\"Dataset memory length: \" + str(mem_len) + \"\\n\")\n",
    "    f.write(\"Data format: \" + data_format + \"\\n\")\n",
    "    f.write(\"Shuffle: \" + str(shuffle) + \"\\n\")\n",
    "    f.write(\"Scale factor: \" + str(scale_factor) + \"\\n\")\n",
    "    f.write(\"Number of features: \" + str(ds.feat_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Reading file 5 of 5\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Creating network...\n",
      "Building input...\n",
      "Building encoder...\n",
      "Building decoder...\n",
      "Building output...\n",
      "Building losses and summaries...\n",
      "------------\n",
      "Training\n",
      "------------\n",
      "Epoch   1 of  30\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:09\n",
      "Estimated time remaining: 00:04:29\n",
      "--------------------------------------\n",
      "Epoch   2 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:18\n",
      "Estimated time remaining: 00:04:13\n",
      "--------------------------------------\n",
      "Epoch   3 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:27\n",
      "Estimated time remaining: 00:03:59\n",
      "--------------------------------------\n",
      "Epoch   4 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:36\n",
      "Estimated time remaining: 00:03:56\n",
      "--------------------------------------\n",
      "Epoch   5 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:45\n",
      "Estimated time remaining: 00:03:42\n",
      "--------------------------------------\n",
      "Epoch   6 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:54\n",
      "Estimated time remaining: 00:03:35\n",
      "--------------------------------------\n",
      "Epoch   7 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:03\n",
      "Estimated time remaining: 00:03:24\n",
      "--------------------------------------\n",
      "Epoch   8 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:12\n",
      "Estimated time remaining: 00:03:17\n",
      "--------------------------------------\n",
      "Epoch   9 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:20\n",
      "Estimated time remaining: 00:03:05\n",
      "--------------------------------------\n",
      "Epoch  10 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:29\n",
      "Estimated time remaining: 00:03:01\n",
      "--------------------------------------\n",
      "Epoch  11 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:38\n",
      "Estimated time remaining: 00:02:49\n",
      "--------------------------------------\n",
      "Epoch  12 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:47\n",
      "Estimated time remaining: 00:02:42\n",
      "--------------------------------------\n",
      "Epoch  13 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:01:56\n",
      "Estimated time remaining: 00:02:29\n",
      "--------------------------------------\n",
      "Epoch  14 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:05\n",
      "Estimated time remaining: 00:02:22\n",
      "--------------------------------------\n",
      "Epoch  15 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:14\n",
      "Estimated time remaining: 00:02:13\n",
      "--------------------------------------\n",
      "Epoch  16 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:23\n",
      "Estimated time remaining: 00:02:05\n",
      "--------------------------------------\n",
      "Epoch  17 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:32\n",
      "Estimated time remaining: 00:01:55\n",
      "--------------------------------------\n",
      "Epoch  18 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:41\n",
      "Estimated time remaining: 00:01:47\n",
      "--------------------------------------\n",
      "Epoch  19 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:50\n",
      "Estimated time remaining: 00:01:38\n",
      "--------------------------------------\n",
      "Epoch  20 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:02:59\n",
      "Estimated time remaining: 00:01:29\n",
      "--------------------------------------\n",
      "Epoch  21 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:03:08\n",
      "Estimated time remaining: 00:01:20\n",
      "--------------------------------------\n",
      "Epoch  22 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:03:16\n",
      "Estimated time remaining: 00:01:11\n",
      "--------------------------------------\n",
      "Epoch  23 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:03:25\n",
      "Estimated time remaining: 00:01:03\n",
      "--------------------------------------\n",
      "Epoch  24 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:03:34\n",
      "Estimated time remaining: 00:00:53\n",
      "--------------------------------------\n",
      "Epoch  25 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:03:43\n",
      "Estimated time remaining: 00:00:44\n",
      "--------------------------------------\n",
      "Epoch  26 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:03:52\n",
      "Estimated time remaining: 00:00:35\n",
      "--------------------------------------\n",
      "Epoch  27 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:04:01\n",
      "Estimated time remaining: 00:00:26\n",
      "--------------------------------------\n",
      "Epoch  28 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:04:10\n",
      "Estimated time remaining: 00:00:17\n",
      "--------------------------------------\n",
      "Epoch  29 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:04:19\n",
      "Estimated time remaining: 00:00:08\n",
      "--------------------------------------\n",
      "Epoch  30 of  30\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:04:28\n",
      "Estimated time remaining: 00:00:00\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "desc = \"y_hat bias shape changed to per source (rather than [1, 1, 1, 1])\"\n",
    "input_dir=\"../../data/Bach10/features/1025/train/Mixtures/\"\n",
    "target_dir=\"../../data/Bach10/features/1025/train/Sources/\"\n",
    "results_dir = \"../../results/trial_27/train_data/\"\n",
    "make_directory(results_dir)\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "time_context = 30\n",
    "mem_len = 5e5\n",
    "data_format = \"NCHW\"\n",
    "mean_loss = False\n",
    "#sources = ['bass', 'drums', 'other', 'vocal'] # DSD100\n",
    "sources = ['violin', 'clarinet', 'saxphone', 'bassoon'] # Bach10\n",
    "shuffle = True\n",
    "scale_factor = 0.2\n",
    "\n",
    "# Create dataset\n",
    "print(\"Creating dataset...\")\n",
    "ds = Dataset(input_dir=input_dir, \n",
    "              target_dir=target_dir, \n",
    "              batch_size=batch_size,\n",
    "              time_context=time_context,\n",
    "              mem_len=mem_len,\n",
    "              load_by_file=False,\n",
    "              sources=sources,\n",
    "              data_format=data_format,\n",
    "              shuffle=shuffle,\n",
    "              scale_factor=scale_factor,\n",
    "              verbose=True)\n",
    "\n",
    "# Create network\n",
    "print(\"Creating network...\")\n",
    "net = Network(results_dir,\n",
    "              data_format=data_format,\n",
    "              time_context=time_context,\n",
    "              feat_size=ds.feat_size,\n",
    "              num_sources=ds.num_sources,\n",
    "              alpha=learning_rate,\n",
    "              mean_loss=mean_loss,\n",
    "              train_mode=True)\n",
    "\n",
    "# Save settings\n",
    "save_train_details(results_dir, desc)\n",
    "\n",
    "print(\"------------\\nTraining\\n------------\")\n",
    "start_time = time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch %3d of %3d\" % (epoch+1, num_epochs))\n",
    "    epoch_start_time = time()\n",
    "    if epoch > 0:\n",
    "        ds.reset_database()\n",
    "    t = 0\n",
    "    while not ds.is_empty():\n",
    "        #sys.stdout.write(\"\\rEstimated batches remaining: \" + str(ds.remaining_batches()))\n",
    "        #sys.stdout.flush()\n",
    "        print(\"Estimated batches remaining: %3d\" % ds.remaining_batches(), end=\"\\r\")\n",
    "        \n",
    "        # Get batch from input data and target data\n",
    "        input_batch, target_batch = ds.create_batch()\n",
    "        \n",
    "        # Perform training step and save summaries every so often\n",
    "        loss = net.perform_training_step(input_batch, target_batch)\n",
    "        if t % 100 == 0:\n",
    "            net.save_summaries(input_batch, target_batch)\n",
    "        \n",
    "        t += 1\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    net.save_model(epoch+1, save_meta=(epoch==0))\n",
    "    \n",
    "    # TODO: this isn't accurate, doesn't take loading data into account\n",
    "    print(\"Epoch complete                        \")\n",
    "    end_time = time()\n",
    "    elap_time = end_time - start_time\n",
    "    rem_time = (end_time - epoch_start_time) * (num_epochs - (epoch + 1))\n",
    "    print(\"Elapsed time: %02d:%02d:%02d\" % (elap_time // 3600, \n",
    "                                            elap_time % 3600 // 60, \n",
    "                                            elap_time % 3600 % 60))\n",
    "    print(\"Estimated time remaining: %02d:%02d:%02d\" % (rem_time // 3600, \n",
    "                                                        rem_time % 3600 // 60, \n",
    "                                                        rem_time % 3600 % 60))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_test_details(folder, desc):\n",
    "    f = open(folder + \"settings.txt\", \"w+\")\n",
    "    f.write(\"Description: \" + desc + \"\\n\")\n",
    "    f.write(\"Input: \" + input_dir + \"\\n\")\n",
    "    f.write(\"Output: \" + target_dir + \"\\n\")\n",
    "    f.write(\"Params: \" + params_file + \"\\n\")\n",
    "    f.write(\"Loss type: \" + (\"mean\" if mean_loss else \"sum\") + \"\\n\")\n",
    "    f.write(\"Batch size: \" + str(batch_size) + \"\\n\")\n",
    "    f.write(\"Time context: \" + str(time_context) + \"\\n\")\n",
    "    f.write(\"Dataset memory length: \" + str(mem_len) + \"\\n\")\n",
    "    f.write(\"Data format: \" + data_format + \"\\n\")\n",
    "    f.write(\"Shuffle: \" + str(shuffle) + \"\\n\")\n",
    "    f.write(\"Scale factor: \" + str(scale_factor) + \"\\n\")\n",
    "    f.write(\"Number of features: \" + str(ds.feat_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Reading file 5 of 5\n",
      "Loading files 1 to 1 of 5 into memory...\n",
      "Creating network...\n",
      "Building input...\n",
      "Building encoder...\n",
      "Building decoder...\n",
      "Building output...\n",
      "Building losses and summaries...\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trial_27/train_data/model-30\n",
      "------------\n",
      "Testing\n",
      "------------\n",
      "File 1 loss: 57.5643; saving results...           \n",
      "Loading files 2 to 2 of 5 into memory...\n",
      "File 2 loss: 99.2381; saving results...           \n",
      "Loading files 3 to 3 of 5 into memory...\n",
      "File 3 loss: 62.1705; saving results...           \n",
      "Loading files 4 to 4 of 5 into memory...\n",
      "File 4 loss: 88.5627; saving results...           \n",
      "Loading files 5 to 5 of 5 into memory...\n",
      "File 5 loss: 84.9008; saving results...           \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Testing settings\n",
    "desc = \"base network\"\n",
    "input_dir=\"../../data/Bach10/features/1025/train/Mixtures/\"\n",
    "target_dir = \"../../data/Bach10/features/1025/train/Sources/\"\n",
    "results_dir = \"../../results/trial_27/test_data/train/\"\n",
    "make_directory(results_dir)\n",
    "params_file = \"../../results/trial_27/train_data/model-30\"\n",
    "batch_size = 32\n",
    "time_context = 30\n",
    "mem_len = 5e5\n",
    "data_format = \"NCHW\"\n",
    "mean_loss = False\n",
    "#sources = ['bass', 'drums', 'other', 'vocal'] # DSD100\n",
    "sources = ['violin', 'clarinet', 'saxphone', 'bassoon'] # Bach10\n",
    "shuffle = False\n",
    "scale_factor = 0.2\n",
    "\n",
    "# Create dataset\n",
    "print(\"Creating dataset...\")\n",
    "ds = Dataset(input_dir=input_dir, \n",
    "              target_dir=target_dir, \n",
    "              batch_size=batch_size,\n",
    "              time_context=time_context,\n",
    "              mem_len=mem_len,\n",
    "              load_by_file=True,\n",
    "              sources=sources,\n",
    "              data_format=data_format,\n",
    "              shuffle=shuffle,\n",
    "              scale_factor=scale_factor,\n",
    "              verbose=True)\n",
    "\n",
    "# Create network\n",
    "print(\"Creating network...\")\n",
    "net = Network(results_dir + \"Network/\",\n",
    "              params_file=params_file,\n",
    "              data_format=data_format,\n",
    "              time_context=time_context,\n",
    "              feat_size=ds.feat_size,\n",
    "              num_sources=ds.num_sources,\n",
    "              mean_loss=mean_loss,\n",
    "              train_mode=False)\n",
    "\n",
    "# Save settings\n",
    "save_test_details(results_dir, desc)\n",
    "\n",
    "print(\"------------\\nTesting\\n------------\")\n",
    "t = 0 # batch iteration\n",
    "pred = []\n",
    "loss = 0\n",
    "while not ds.is_empty():\n",
    "    start_time = time()\n",
    "    #sys.stdout.write(\"\\rEstimated batches remaining: \" + str(ds.remaining_batches()))\n",
    "    #sys.stdout.flush()\n",
    "    print(\"Estimated files remaining: %3d\" % ds.remaining_files(), end=\"\\r\")\n",
    "\n",
    "    # Get batch from input data and target data\n",
    "    input_batch, target_batch = ds.create_batch()\n",
    "    \n",
    "    # Make prediction\n",
    "    pred_, loss_ = net.predict(input_batch, target_batch)\n",
    "    \n",
    "    # Store prediction and loss\n",
    "    pred.append(np.reshape(pred_, [-1, ds.feat_size, ds.num_sources]))\n",
    "    loss += loss_\n",
    "\n",
    "    # Save prediction if reached end of current file\n",
    "    if ds.load_next or ds.reset:\n",
    "        print(\"File %d loss: %.4f; saving results...           \" % (t+1, loss / len(pred)))\n",
    "       \n",
    "        # Get last window\n",
    "        if data_format == \"NCHW\":\n",
    "            input_shape = [1, 1, time_context, -1]\n",
    "            target_shape = [1, ds.num_sources, time_context, -1]\n",
    "        elif data_format == \"NHWC\":\n",
    "            input_shape = [1, time_context, 1, -1]\n",
    "            target_shape = [1, time_context, ds.num_sources, -1]\n",
    "        last_input = np.reshape(ds.inputs_[-time_context:], input_shape)\n",
    "        last_target = np.reshape(ds.sources_[-time_context:], target_shape)\n",
    "        pred_, _ = net.predict(last_input, last_target)\n",
    "        pred_ = np.reshape(pred_, [-1, ds.feat_size, ds.num_sources])\n",
    "    \n",
    "        # Add last window to predictions, averaging overlapping time points\n",
    "        pred = np.concatenate(pred, axis=0)\n",
    "        overlap = ds.shapes[t, 0] - pred.shape[0]\n",
    "        if overlap == 0: overlap = None\n",
    "        pred[-time_context:-overlap] = \\\n",
    "            (pred[-time_context:-overlap] + pred_[:-overlap]) / 2.0\n",
    "        pred = np.concatenate([pred, pred_[-overlap:]], axis=0)\n",
    "       \n",
    "        # Save source predictions\n",
    "        for i, s in enumerate(sources):\n",
    "            filename = os.path.split(ds.input_files[t])[-1]\n",
    "            base = filename.split('.')[0]\n",
    "            np.save(results_dir + \"Spectrograms/\" base + \"-%s-pred\" % s, pred[:, :, i])\n",
    "        \n",
    "        # Increment counters\n",
    "        loss = 0\n",
    "        pred = []\n",
    "        t += 1\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Old code\n",
    "Just stashing away old code in case I need to reference or pull from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal']):\n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir)])\n",
    "        target_files = sorted([os.path.join(target_dir, f) for f in os.listdir(target_dir)])\n",
    "        self.source_files = []\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "\n",
    "        # Get shapes of data files\n",
    "        input_shapes = []\n",
    "        for f in self.input_files:\n",
    "            input_shapes.append(np.load(f, mmap_mode='r').shape)\n",
    "        input_shapes = np.asarray(input_shapes)\n",
    "        self.t_total = np.sum(input_shapes[:, 0])\n",
    "        self.feat_size = input_shapes[0, 1]\n",
    "        if not (input_shapes[:, 1] == self.feat_size).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        \n",
    "        # Create memmap array of all files\n",
    "        # From https://stackoverflow.com/questions/13780907/is-it-possible-to-np-concatenate-memory-mapped-files\n",
    "        # Initialize memmap objects\n",
    "        self.inputs = np.memmap(self.input_files[0], \n",
    "                                dtype='float64',\n",
    "                                mode='r+',\n",
    "                                shape=(self.t_total, self.feat_size),\n",
    "                                order='C')\n",
    "        self.sources = []\n",
    "        for i in range(len(sources)):\n",
    "            self.sources.append(np.memmap(self.source_files[i][0], \n",
    "                                          dtype='float64',\n",
    "                                          mode='r+',\n",
    "                                          shape=(self.t_total, self.feat_size),\n",
    "                                          order='C'))\n",
    "        \n",
    "        # Read values from subsequent files into initialized memmap\n",
    "        idx = input_shapes[0, 0]\n",
    "        for i in range(1, len(self.input_files)):\n",
    "            print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            # Load mem map of mixture file\n",
    "            #f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            f_in = np.memmap(self.input_files[i],\n",
    "                            dtype='float64',\n",
    "                                mode='r',\n",
    "                                shape=(input_shapes[i,0], self.feat_size),\n",
    "                                order='C')\n",
    "            self.inputs[idx:idx+f_in.shape[0]] = f_in\n",
    "            \n",
    "            # Load mem maps of source files\n",
    "            for j in range(len(sources)):\n",
    "                #f_s = np.load(self.source_files[j][i], mmap_mode='r')\n",
    "                f_s = np.memmap(self.source_files[j][i],\n",
    "                                dtype='float64',\n",
    "                                mode='r',\n",
    "                                shape=(input_shapes[i,0], self.feat_size),\n",
    "                                order='C')\n",
    "                self.sources[j][idx:idx+f_s.shape[0]] = f_s\n",
    "            \n",
    "            # Increment index\n",
    "            idx += f_in.shape[0]\n",
    "        \n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        idx_start = self.t\n",
    "        self.inputs_ = self.inputs[self.t:min(self.t+self.mem_len, self.t_total)]\n",
    "        self.sources_ = [s[self.t:min(self.t+self.mem_len, self.t_total)] \n",
    "                         for s in self.sources]\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def reset_database(self):\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Reset database if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        \n",
    "        # Load more data into memory if needed\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        self.reset = False\n",
    "        if self.t + batch_len > self.t_total:\n",
    "            batch_len = self.t_total - self.t\n",
    "            self.reset = True\n",
    "        elif self.t_ + batch_len > self.inputs_.shape[0]:\n",
    "            self.load_memory()\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[self.t_:self.t_+batch_len],\n",
    "                                  [self.batch_size, self.time_context, self.feat_size])\n",
    "        sources_batch = [np.reshape(s[self.t_:self.t_+batch_len],\n",
    "                                    [self.batch_size, self.time_context, self.feat_size])\n",
    "                         for s in self.sources_]\n",
    "        self.t_ += batch_len\n",
    "        self.t  += batch_len\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal'],\n",
    "                 data_format=\"NHWC\",\n",
    "                 shuffle_len=30,\n",
    "                 verbose=True):\n",
    "        # Grab arguments\n",
    "        self.batch_size = batch_size\n",
    "        self.time_context = time_context\n",
    "        self.num_sources = len(sources)\n",
    "        self.data_format = data_format\n",
    "        self.shuffle_len = shuffle_len\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) \n",
    "                                   for f in os.listdir(input_dir) if \"mag\" in f])\n",
    "        target_files = sorted([os.path.join(target_dir, f) \n",
    "                               for f in os.listdir(target_dir) if \"mag\" in f])\n",
    "        self.source_files = [] # [source_id][t]\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "        \n",
    "        # Read mem maps of data files\n",
    "        self.inputs = []\n",
    "        self.sources = [] # [t][source_id]\n",
    "        self.shapes = []\n",
    "        shapes_ = [] # placeholder to ensure all associated shapes equal\n",
    "        for i in range(len(self.input_files)):\n",
    "            if verbose:\n",
    "                print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            \n",
    "            # Add mem map of mixture file\n",
    "            f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            self.inputs.append(f_in)\n",
    "            \n",
    "            # Add mem maps of source files\n",
    "            f_s = [np.load(self.source_files[j][i], mmap_mode='r') \n",
    "                   for j in range(len(sources))]\n",
    "            self.sources.append(f_s)\n",
    "            \n",
    "            # Get shapes\n",
    "            self.shapes.append(f_in.shape)\n",
    "            shapes_.append([f.shape for f in f_s])\n",
    "        \n",
    "        # Set class variables\n",
    "        self.shapes = np.asarray(self.shapes)\n",
    "        self.t_total = np.sum(self.shapes[:, 0])\n",
    "        self.feat_size = self.shapes[0, 1]\n",
    "        \n",
    "        # Check that shapes [index, ch, shape] are equal for each time point\n",
    "        shapes_ = np.concatenate([self.shapes[:, np.newaxis, :], np.asarray(shapes_)], axis=1)\n",
    "        if not (shapes_[:, :, 0].T == shapes_[:, 0, 0]).all():\n",
    "            raise ValueError(\"All spectrograms must be of same length.\")\n",
    "        if not (shapes_[:, :, 1].T == shapes_[:, 0, 1]).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        shapes_ = None # release from memory\n",
    "            \n",
    "        # Set variables to track time position\n",
    "        self.t_c = np.cumsum(self.shapes[:, 0])\n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_next = False # if True, load next batch of files\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        # Get indices of files corresponding to next mem_len time points\n",
    "        t_start = self.t\n",
    "        t_end = self.t + self.mem_len\n",
    "        idx_start = np.searchsorted(self.t_c, t_start, side='right')\n",
    "        idx_end = np.searchsorted(self.t_c, t_end, side='right')\n",
    "        if self.verbose:\n",
    "            #print(\"Indices t %d to %d\" % (t_start, t_end))\n",
    "            print(\"Loading files %d to %d of %d into memory...\" % (idx_start+1, idx_end, len(self.inputs)))\n",
    "        \n",
    "        # Load from mem maps of files into shape [time, features, [num_sources]]\n",
    "        f_in = [self.inputs[t] for t in range(idx_start, idx_end)] # get list of next files\n",
    "        self.inputs_ = None # clear previous memory (avoids temporary double storage)\n",
    "        self.inputs_ = np.concatenate(f_in, axis=0) # loads into memory\n",
    "        f_s = [np.asarray(self.sources[t]) for t in range(idx_start, idx_end)]\n",
    "        self.sources_ = None\n",
    "        self.sources_ = np.transpose(np.concatenate(f_s, axis=1), axes=[1, 2, 0]) # loads into memory\n",
    "                                          \n",
    "        # Reset counter\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def reset_database(self):\n",
    "        if self.verbose:\n",
    "            print(\"Resetting database...\")\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Load memory if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        elif self.load_next:\n",
    "            self.load_memory()\n",
    "        \n",
    "        # Determine batch length and set loading bools for next batch\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        rem = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        if self.t + batch_len > self.t_total: # reach end of all data\n",
    "            batch_len = (self.t_total - self.t) // self.time_context * self.time_context\n",
    "            rem = (self.t_total - self.t) % self.time_context\n",
    "            self.reset = True\n",
    "        elif self.t_ + batch_len > self.inputs_.shape[0]: # reach end of loaded data\n",
    "            batch_len = (self.inputs_.shape[0] - self.t_) // self.time_context * self.time_context\n",
    "            rem = (self.inputs_.shape[0] - self.t_) % self.time_context\n",
    "            self.load_next = True\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[self.t_:self.t_+batch_len],\n",
    "                                  [-1, self.time_context, self.feat_size, 1])\n",
    "        sources_batch = np.reshape(self.sources_[self.t_:self.t_+batch_len],\n",
    "                                    [-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        if self.data_format == \"NCHW\":\n",
    "            inputs_batch = np.transpose(inputs_batch, axes=[0, 3, 1, 2])\n",
    "            sources_batch = np.transpose(sources_batch, axes=[0, 3, 1, 2])\n",
    "        \n",
    "        # Increment counters\n",
    "        self.t_ += batch_len + rem \n",
    "        self.t  += batch_len + rem\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return ds.reset\n",
    "    \n",
    "    def remaining_batches(self):\n",
    "        return math.ceil((self.inputs_.shape[0] - self.t_) \n",
    "                         / (self.batch_size * self.time_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal'],\n",
    "                 data_format=\"NHWC\",\n",
    "                 shuffle_len=30,\n",
    "                 verbose=True):\n",
    "        # Grab arguments\n",
    "        self.batch_size = batch_size\n",
    "        self.time_context = time_context\n",
    "        self.num_sources = len(sources)\n",
    "        self.data_format = data_format\n",
    "        self.shuffle_len = shuffle_len\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) \n",
    "                                   for f in os.listdir(input_dir) if \"mag\" in f])\n",
    "        target_files = sorted([os.path.join(target_dir, f) \n",
    "                               for f in os.listdir(target_dir) if \"mag\" in f])\n",
    "        self.source_files = [] # [source_id][t]\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "        \n",
    "        # Read mem maps of data files\n",
    "        self.inputs = []\n",
    "        self.sources = [] # [t][source_id]\n",
    "        self.shapes = []\n",
    "        shapes_ = [] # placeholder to ensure all associated shapes equal\n",
    "        for i in range(len(self.input_files)):\n",
    "            if verbose:\n",
    "                print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            \n",
    "            # Add mem map of mixture file\n",
    "            f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            self.inputs.append(f_in)\n",
    "            \n",
    "            # Add mem maps of source files\n",
    "            f_s = [np.load(self.source_files[j][i], mmap_mode='r') \n",
    "                   for j in range(len(sources))]\n",
    "            self.sources.append(f_s)\n",
    "            \n",
    "            # Get shapes\n",
    "            self.shapes.append(f_in.shape)\n",
    "            shapes_.append([f.shape for f in f_s])\n",
    "        \n",
    "        # Set class variables\n",
    "        self.shapes = np.asarray(self.shapes)\n",
    "        self.t_total = np.sum(self.shapes[:, 0])\n",
    "        self.feat_size = self.shapes[0, 1]\n",
    "        \n",
    "        # Check that shapes [index, ch, shape] are equal for each time point\n",
    "        shapes_ = np.concatenate([self.shapes[:, np.newaxis, :], np.asarray(shapes_)], axis=1)\n",
    "        if not (shapes_[:, :, 0].T == shapes_[:, 0, 0]).all():\n",
    "            raise ValueError(\"All spectrograms must be of same length.\")\n",
    "        if not (shapes_[:, :, 1].T == shapes_[:, 0, 1]).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        shapes_ = None # release from memory\n",
    "            \n",
    "        # Set variables to track time position\n",
    "        self.t_c = np.cumsum(self.shapes[:, 0])\n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_next = False # if True, load next batch of files\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        # Get indices of files corresponding to next mem_len time points\n",
    "        t_start = self.t\n",
    "        t_end = self.t + self.mem_len\n",
    "        idx_start = np.searchsorted(self.t_c, t_start, side='right')\n",
    "        idx_end = np.searchsorted(self.t_c, t_end, side='right')\n",
    "        if self.verbose:\n",
    "            print(\"Loading files %d to %d of %d into memory...\" % (idx_start+1, idx_end, len(self.inputs)))\n",
    "        \n",
    "        # Load from mem maps of files into shape [time, features, [num_sources]]\n",
    "        f_in = [self.inputs[t] for t in range(idx_start, idx_end)] # get list of next files\n",
    "        self.inputs_ = None # clear previous memory (avoids temporary double storage)\n",
    "        self.inputs_ = np.concatenate(f_in, axis=0) # loads into memory\n",
    "        f_s = [np.asarray(self.sources[t]) for t in range(idx_start, idx_end)]\n",
    "        self.sources_ = None\n",
    "        self.sources_ = np.transpose(np.concatenate(f_s, axis=1), axes=[1, 2, 0]) # loads into memory\n",
    "                                          \n",
    "        # Set vector of random start points from loaded memory\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        self.t_rand = np.asarray([batch_len * n \n",
    "                                  for n in range(self.inputs_.shape[0] // batch_len + 1)])\n",
    "        np.random.shuffle(self.t_rand)\n",
    "        self.t_idx = 0\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def reset_database(self):\n",
    "        if self.verbose:\n",
    "            print(\"Resetting database...\")\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Load memory if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        elif self.load_next:\n",
    "            self.load_memory()\n",
    "\n",
    "        # Determine batch length and set loading bools for next batch\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        rem = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        t_i = self.t_rand[self.t_idx]\n",
    "        if self.t + batch_len >= self.t_total: # reach end of all data\n",
    "            #batch_len = (self.t_total - self.t) // self.time_context * self.time_context\n",
    "            #rem = (self.t_total - self.t) % self.time_context\n",
    "            self.reset = True\n",
    "        if t_i + batch_len >= self.inputs_.shape[0]: # reach end of loaded data\n",
    "            batch_len = (self.inputs_.shape[0] - t_i) // self.time_context * self.time_context\n",
    "            rem = (self.inputs_.shape[0] - t_i) % self.time_context\n",
    "        if self.t_idx >= len(self.t_rand) - 1: # exhausted all loaded data\n",
    "            self.load_next = True\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[t_i:t_i+batch_len],\n",
    "                                  [-1, self.time_context, self.feat_size, 1])\n",
    "        sources_batch = np.reshape(self.sources_[t_i:t_i+batch_len],\n",
    "                                    [-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        if self.data_format == \"NCHW\":\n",
    "            inputs_batch = np.transpose(inputs_batch, axes=[0, 3, 1, 2])\n",
    "            sources_batch = np.transpose(sources_batch, axes=[0, 3, 1, 2])\n",
    "        \n",
    "        # Increment counters\n",
    "        self.t  += batch_len + rem\n",
    "        self.t_ += batch_len + rem\n",
    "        self.t_idx += 1\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return ds.reset\n",
    "    \n",
    "    def remaining_batches(self):\n",
    "        return math.ceil((self.inputs_.shape[0] - self.t_) \n",
    "                         / (self.batch_size * self.time_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old batch handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batches(data, batch_size):\n",
    "    \"\"\"Reshapes data into batches of input size for network\"\"\"\n",
    "    batches = []\n",
    "    time_batches = data.shape[1] // time_context\n",
    "    freq_batches = data.shape[2] // feat_size\n",
    "    for t in range(time_batches):\n",
    "        for f in range(freq_batches):\n",
    "            batches.append(data[:, t*time_context:(t+1)*time_context, f*feat_size:(f+1)*feat_size])\n",
    "    return np.asarray(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "params_dir = results_dir + \"params/\"\n",
    "make_directory(params_dir)\n",
    "input_file = \"./features/02-AchLiebenChristen__m_.data\"\n",
    "shape_file = \"./features/02-AchLiebenChristen__m_.shape\"\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "f_in = np.fromfile(input_file)\n",
    "if shape_file is not None:\n",
    "    f_shape = get_shape(shape_file)\n",
    "    f_in = np.reshape(f_in, f_shape)\n",
    "input_data = create_batches(f_in[0:1], batch_size) # mixed input\n",
    "target_data = create_batches(f_in[1:], batch_size) # separate sources\n",
    "iter_size = len(input_data) // batch_size\n",
    "\n",
    "# Initialize graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(iter_size):\n",
    "        # Get batch from input data and target data\n",
    "        input_batch = input_data[i*batch_size:(i+1)*batch_size] # magnitude spectrogram of whole\n",
    "        target_batch = target_data[i*batch_size:(i+1)*batch_size] # magnitude spectrogram of sources\n",
    "        \n",
    "        # Perform training step\n",
    "        feed_dict = {spectrogram: input_batch, targets: target_batch}\n",
    "        loss_sum_, _ = sess.run([loss_sum, train_step], \n",
    "                                feed_dict=feed_dict)\n",
    "        writer.add_summary(loss_sum_, global_step=global_step)\n",
    "        writer.flush()\n",
    "        global_step += 1\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    saver.save(sess, params_dir + \"model\", \n",
    "               global_step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset testing (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file 1 of 5\n",
      "Reading file 2 of 5\n",
      "Reading file 3 of 5\n",
      "Reading file 4 of 5\n",
      "Reading file 5 of 5\n",
      "Indices t 0 to 100000\n",
      "Loading files 1 to 2 of 5 into memory...\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(input_dir='../../data/DSD100/features_mini/Mixtures/Dev/', \n",
    "             target_dir='../../data/DSD100/features_mini/Sources/Dev/', \n",
    "             batch_size=32,\n",
    "             time_context=30,\n",
    "             sources=['bass', 'drums', 'other', 'vocal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1, t 0, t_ 0\n",
      "Batch 2, t 960, t_ 960\n",
      "Batch 3, t 1920, t_ 1920\n",
      "Batch 4, t 2880, t_ 2880\n",
      "Batch 5, t 3840, t_ 3840\n",
      "Batch 6, t 4800, t_ 4800\n",
      "Batch 7, t 5760, t_ 5760\n",
      "Batch 8, t 6720, t_ 6720\n",
      "Batch 9, t 7680, t_ 7680\n",
      "Batch 10, t 8640, t_ 8640\n",
      "Batch 11, t 9600, t_ 9600\n",
      "Batch 12, t 10560, t_ 10560\n",
      "Batch 13, t 11520, t_ 11520\n",
      "Batch 14, t 12480, t_ 12480\n",
      "Batch 15, t 13440, t_ 13440\n",
      "Batch 16, t 14400, t_ 14400\n",
      "Batch 17, t 15360, t_ 15360\n",
      "Batch 18, t 16320, t_ 16320\n",
      "Batch 19, t 17280, t_ 17280\n",
      "Batch 20, t 18240, t_ 18240\n",
      "Batch 21, t 19200, t_ 19200\n",
      "Batch 22, t 20160, t_ 20160\n",
      "Batch 23, t 21120, t_ 21120\n",
      "Batch 24, t 22080, t_ 22080\n",
      "Batch 25, t 23040, t_ 23040\n",
      "Batch 26, t 24000, t_ 24000\n",
      "Batch 27, t 24960, t_ 24960\n",
      "Batch 28, t 25920, t_ 25920\n",
      "Batch 29, t 26880, t_ 26880\n",
      "Batch 30, t 27840, t_ 27840\n",
      "Batch 31, t 28800, t_ 28800\n",
      "Batch 32, t 29760, t_ 29760\n",
      "Batch 33, t 30720, t_ 30720\n",
      "Batch 34, t 31680, t_ 31680\n",
      "Batch 35, t 32640, t_ 32640\n",
      "Batch 36, t 33600, t_ 33600\n",
      "Batch 37, t 34560, t_ 34560\n",
      "Batch 38, t 35520, t_ 35520\n",
      "Batch 39, t 36480, t_ 36480\n",
      "Batch 40, t 37440, t_ 37440\n",
      "Batch 41, t 38400, t_ 38400\n",
      "Batch 42, t 39360, t_ 39360\n",
      "Batch 43, t 40320, t_ 40320\n",
      "Batch 44, t 41280, t_ 41280\n",
      "Batch 45, t 42240, t_ 42240\n",
      "Batch 46, t 43200, t_ 43200\n",
      "Batch 47, t 44160, t_ 44160\n",
      "Batch 48, t 45120, t_ 45120\n",
      "Batch 49, t 46080, t_ 46080\n",
      "Batch 50, t 47040, t_ 47040\n",
      "Batch 51, t 48000, t_ 48000\n",
      "Batch 52, t 48960, t_ 48960\n",
      "Batch 53, t 49920, t_ 49920\n",
      "Batch 54, t 50880, t_ 50880\n",
      "Batch 55, t 51840, t_ 51840\n",
      "Batch 56, t 52800, t_ 52800\n",
      "Batch 57, t 53760, t_ 53760\n",
      "Batch 58, t 54720, t_ 54720\n",
      "Batch 59, t 55680, t_ 55680\n",
      "Batch 60, t 56640, t_ 56640\n",
      "Batch 61, t 57600, t_ 57600\n",
      "Batch 62, t 58560, t_ 58560\n",
      "Batch 63, t 59520, t_ 59520\n",
      "Batch 64, t 60480, t_ 60480\n",
      "Batch 65, t 61440, t_ 61440\n",
      "Batch 66, t 62400, t_ 62400\n",
      "Batch 67, t 63360, t_ 63360\n",
      "Batch 68, t 64320, t_ 64320\n",
      "Batch 69, t 65280, t_ 65280\n",
      "Batch 70, t 66240, t_ 66240\n",
      "Batch 71, t 67200, t_ 67200\n",
      "Batch 72, t 68160, t_ 68160\n",
      "Batch 73, t 69120, t_ 69120\n",
      "Batch 74, t 70080, t_ 70080\n",
      "Batch 75, t 71040, t_ 71040\n",
      "Batch 76, t 71626, t_ 71626\n",
      "Indices t 71626 to 171626\n",
      "Loading files 3 to 5 of 5 into memory...\n",
      "Batch 77, t 72586, t_ 960\n",
      "Batch 78, t 73546, t_ 1920\n",
      "Batch 79, t 74506, t_ 2880\n",
      "Batch 80, t 75466, t_ 3840\n",
      "Batch 81, t 76426, t_ 4800\n",
      "Batch 82, t 77386, t_ 5760\n",
      "Batch 83, t 78346, t_ 6720\n",
      "Batch 84, t 79306, t_ 7680\n",
      "Batch 85, t 80266, t_ 8640\n",
      "Batch 86, t 81226, t_ 9600\n",
      "Batch 87, t 82186, t_ 10560\n",
      "Batch 88, t 83146, t_ 11520\n",
      "Batch 89, t 84106, t_ 12480\n",
      "Batch 90, t 85066, t_ 13440\n",
      "Batch 91, t 86026, t_ 14400\n",
      "Batch 92, t 86986, t_ 15360\n",
      "Batch 93, t 87946, t_ 16320\n",
      "Batch 94, t 88906, t_ 17280\n",
      "Batch 95, t 89866, t_ 18240\n",
      "Batch 96, t 90826, t_ 19200\n",
      "Batch 97, t 91786, t_ 20160\n",
      "Batch 98, t 92746, t_ 21120\n",
      "Batch 99, t 93706, t_ 22080\n",
      "Batch 100, t 94666, t_ 23040\n",
      "Batch 101, t 95626, t_ 24000\n",
      "Batch 102, t 96586, t_ 24960\n",
      "Batch 103, t 97546, t_ 25920\n",
      "Batch 104, t 98506, t_ 26880\n",
      "Batch 105, t 99466, t_ 27840\n",
      "Batch 106, t 100426, t_ 28800\n",
      "Batch 107, t 101386, t_ 29760\n",
      "Batch 108, t 102346, t_ 30720\n",
      "Batch 109, t 103306, t_ 31680\n",
      "Batch 110, t 104266, t_ 32640\n",
      "Batch 111, t 105226, t_ 33600\n",
      "Batch 112, t 106186, t_ 34560\n",
      "Batch 113, t 107146, t_ 35520\n",
      "Batch 114, t 108106, t_ 36480\n",
      "Batch 115, t 109066, t_ 37440\n",
      "Batch 116, t 110026, t_ 38400\n",
      "Batch 117, t 110986, t_ 39360\n",
      "Batch 118, t 111946, t_ 40320\n",
      "Batch 119, t 112906, t_ 41280\n",
      "Batch 120, t 113866, t_ 42240\n",
      "Batch 121, t 114826, t_ 43200\n",
      "Batch 122, t 115786, t_ 44160\n",
      "Batch 123, t 116746, t_ 45120\n",
      "Batch 124, t 117706, t_ 46080\n",
      "Batch 125, t 118666, t_ 47040\n",
      "Batch 126, t 119626, t_ 48000\n",
      "Batch 127, t 120586, t_ 48960\n",
      "Batch 128, t 121546, t_ 49920\n",
      "Batch 129, t 122506, t_ 50880\n",
      "Batch 130, t 123466, t_ 51840\n",
      "Batch 131, t 124426, t_ 52800\n",
      "Batch 132, t 125386, t_ 53760\n",
      "Batch 133, t 126346, t_ 54720\n",
      "Batch 134, t 127306, t_ 55680\n",
      "Batch 135, t 128266, t_ 56640\n",
      "Batch 136, t 129226, t_ 57600\n",
      "Batch 137, t 130186, t_ 58560\n",
      "Batch 138, t 131146, t_ 59520\n",
      "Batch 139, t 132106, t_ 60480\n",
      "Batch 140, t 133066, t_ 61440\n",
      "Batch 141, t 134026, t_ 62400\n",
      "Batch 142, t 134986, t_ 63360\n",
      "Batch 143, t 135946, t_ 64320\n",
      "Batch 144, t 136906, t_ 65280\n",
      "Batch 145, t 137866, t_ 66240\n",
      "Batch 146, t 138826, t_ 67200\n",
      "Batch 147, t 139786, t_ 68160\n",
      "Batch 148, t 140746, t_ 69120\n",
      "Batch 149, t 141706, t_ 70080\n",
      "Batch 150, t 142666, t_ 71040\n",
      "Batch 151, t 143626, t_ 72000\n",
      "Batch 152, t 144586, t_ 72960\n",
      "Batch 153, t 145546, t_ 73920\n",
      "Batch 154, t 146506, t_ 74880\n",
      "Batch 155, t 147466, t_ 75840\n",
      "Batch 156, t 148426, t_ 76800\n",
      "Batch 157, t 149386, t_ 77760\n",
      "Batch 158, t 150346, t_ 78720\n",
      "Batch 159, t 151306, t_ 79680\n",
      "Batch 160, t 152266, t_ 80640\n",
      "Batch 161, t 153226, t_ 81600\n",
      "Batch 162, t 154186, t_ 82560\n",
      "Batch 163, t 155146, t_ 83520\n",
      "Batch 164, t 156106, t_ 84480\n",
      "Batch 165, t 157066, t_ 85440\n",
      "Batch 166, t 158026, t_ 86400\n",
      "Batch 167, t 158986, t_ 87360\n",
      "Batch 168, t 159946, t_ 88320\n",
      "Batch 169, t 160906, t_ 89280\n",
      "Batch 170, t 161866, t_ 90240\n",
      "Batch 171, t 162826, t_ 91200\n",
      "Batch 172, t 163786, t_ 92160\n",
      "Batch 173, t 164746, t_ 93120\n",
      "Batch 174, t 165706, t_ 94080\n",
      "Batch 175, t 166666, t_ 95040\n",
      "Batch 176, t 166932, t_ 95306\n",
      "Reseting database...\n",
      "Indices t 0 to 100000\n",
      "Loading files 1 to 2 of 5 into memory...\n",
      "Batch 177, t 960, t_ 960\n",
      "Batch 178, t 1920, t_ 1920\n",
      "Batch 179, t 2880, t_ 2880\n",
      "Batch 180, t 3840, t_ 3840\n",
      "Batch 181, t 4800, t_ 4800\n",
      "Batch 182, t 5760, t_ 5760\n",
      "Batch 183, t 6720, t_ 6720\n",
      "Batch 184, t 7680, t_ 7680\n",
      "Batch 185, t 8640, t_ 8640\n",
      "Batch 186, t 9600, t_ 9600\n",
      "Batch 187, t 10560, t_ 10560\n",
      "Batch 188, t 11520, t_ 11520\n",
      "Batch 189, t 12480, t_ 12480\n",
      "Batch 190, t 13440, t_ 13440\n",
      "Batch 191, t 14400, t_ 14400\n",
      "Batch 192, t 15360, t_ 15360\n",
      "Batch 193, t 16320, t_ 16320\n",
      "Batch 194, t 17280, t_ 17280\n",
      "Batch 195, t 18240, t_ 18240\n",
      "Batch 196, t 19200, t_ 19200\n",
      "Batch 197, t 20160, t_ 20160\n",
      "Batch 198, t 21120, t_ 21120\n",
      "Batch 199, t 22080, t_ 22080\n",
      "Batch 200, t 23040, t_ 23040\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(\"Batch %d, t %d, t_ %d\" % (i+1, ds.t, ds.t_))\n",
    "    _, _ = ds.create_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph building without class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Setttings\n",
    "#data_format = \"NHWC\" # if using cpu\n",
    "data_format = \"NCHW\" # if using gpu\n",
    "results_dir = \"./results/trial_1/\"\n",
    "make_directory(results_dir)\n",
    "time_context = 30\n",
    "feat_size = 513\n",
    "num_sources = 4\n",
    "eps = 1e-18 # numerical stability\n",
    "alpha = 0.001 # learning rate\n",
    "\n",
    "# Data formatting\n",
    "if data_format == \"NHWC\":\n",
    "    input_shape = [None, time_context, feat_size, 1]\n",
    "    target_shape = [None, time_context, feat_size, num_sources]\n",
    "    channel_dim = 3\n",
    "elif data_format == \"NCHW\":\n",
    "    input_shape = [None, 1, time_context, feat_size]\n",
    "    target_shape = [None, num_sources, time_context, feat_size]\n",
    "    channel_dim = 1\n",
    "else:\n",
    "    raise ValueError(\"Unknown data format \\\"\" + data_format + \"\\\"\")\n",
    "spectrogram = tf.placeholder(tf.float32, \n",
    "                             shape=input_shape, \n",
    "                             name=\"magnitude_spectrogram\")\n",
    "\n",
    "# Convolutional layer 1\n",
    "conv1 = conv2d(spectrogram,\n",
    "               num_outputs=30,\n",
    "               kernel_size=[1, 30],\n",
    "               stride=[1, 4],\n",
    "               padding=\"VALID\",\n",
    "               data_format=data_format,\n",
    "               weights_initializer=\"xavier\",\n",
    "               biases_initializer=[\"constant\", 0.0],\n",
    "               scope=\"CONV_1\")\n",
    "\n",
    "# Convolutional layer 2\n",
    "conv2 = conv2d(conv1,\n",
    "               num_outputs=30,\n",
    "               kernel_size=[int(2*time_context/3), 1],\n",
    "               stride=[1, 1],\n",
    "               padding=\"VALID\",\n",
    "               data_format=data_format,\n",
    "               weights_initializer=\"xavier\",\n",
    "               biases_initializer=[\"constant\", 0.0],\n",
    "               scope=\"CONV_2\")\n",
    "conv2_flat = flatten(conv2,\n",
    "                     data_format=data_format,\n",
    "                     scope=\"CONV_2_FLAT\")\n",
    "\n",
    "# Fully-connected layer 1 (encoding)\n",
    "fc1 = fully_connected(conv2_flat,\n",
    "                      num_outputs=256,\n",
    "                      activation_fn=\"relu\",\n",
    "                      weights_initializer=\"xavier\",\n",
    "                      biases_initializer=[\"constant\", 0.0],\n",
    "                      scope=\"FC_1\")\n",
    "\n",
    "# Get shapes for building decoding layers\n",
    "batch_size = tf.shape(spectrogram)[0]\n",
    "conv1_shape = conv1.get_shape().as_list()\n",
    "conv2_shape = conv2.get_shape().as_list()\n",
    "conv2_size = conv2_shape[1] * conv2_shape[2] * conv2_shape[3]\n",
    "\n",
    "# Build decoder for each source\n",
    "fc2, convt1, convt2 = [], [], []\n",
    "for i in range(num_sources):\n",
    "    # Fully-connected layer 2 (decoding)\n",
    "    fc2_i = fully_connected(fc1,\n",
    "                            num_outputs=conv2_size,\n",
    "                            activation_fn=\"relu\",\n",
    "                            weights_initializer=\"xavier\",\n",
    "                            biases_initializer=[\"constant\", 0.0],\n",
    "                            scope=\"FC_2_%d\" % (i+1))\n",
    "    fc2.append(fc2_i)\n",
    "    \n",
    "    # Convolutional transpose layer 1\n",
    "    # Side note: tf.reshape() can infer size of one dimension given rest, so -1 okay\n",
    "    #            tf.nn.conv2d_transpose() must know exact dimensions, but batch size can\n",
    "    #                be inferred at runtime using tf.shape()\n",
    "    fc2_i = tf.reshape(fc2_i, [-1] + conv2_shape[1:])\n",
    "    convt1_i = conv2d_transpose(fc2_i,\n",
    "                                output_shape=[batch_size] + conv1_shape[1:],\n",
    "                                kernel_size=[int(2*time_context/3), 1],\n",
    "                                stride=[1, 1],\n",
    "                                padding=\"VALID\",\n",
    "                                data_format=data_format,\n",
    "                                weights_initializer=\"xavier\",\n",
    "                                biases_initializer=[\"constant\", 0.0],\n",
    "                                scope=\"CONVT_1_%d\" % (i+1))\n",
    "    convt1.append(convt1_i)\n",
    "    \n",
    "    # Convolutional transpose layer 2\n",
    "    convt2_i = conv2d_transpose(convt1_i,\n",
    "                                output_shape=[batch_size] + input_shape[1:],\n",
    "                                kernel_size=[1, 30],\n",
    "                                stride=[1, 4],\n",
    "                                padding=\"VALID\",\n",
    "                                data_format=data_format,\n",
    "                                weights_initializer=\"xavier\",\n",
    "                                biases_initializer=[\"constant\", 0.0],\n",
    "                                scope=\"CONVT_2_%d\" % (i+1))\n",
    "    convt2.append(convt2_i)\n",
    "\n",
    "# Output layer\n",
    "with tf.name_scope(\"y_hat\"):\n",
    "    convt2_all = tf.concat(convt2, axis=channel_dim)\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[1, 1, 1, 1]),\n",
    "                    dtype=tf.float32,\n",
    "                    name=\"bias\")\n",
    "    y_hat = tf.maximum(tf.add(convt2_all, b), 0, name=\"y_hat\")\n",
    "\n",
    "# Masks: m_n(f) = |y_hat_n(f)| / Σ(|y_hat_n'(f)|)\n",
    "with tf.name_scope(\"masks\"):\n",
    "    rand = tf.random_uniform([batch_size] + input_shape[1:])\n",
    "    den = tf.reduce_sum(y_hat, axis=channel_dim, keep_dims=True) + (eps * rand)\n",
    "    masks = tf.div(y_hat, den, name=\"masks\") # broadcast along channel dimension\n",
    "    \n",
    "# Source signals: y_tilde_n(f) = m_n(f) * x(f), \n",
    "# where x(f) is the spectrogram of the input mixture signal\n",
    "with tf.name_scope(\"y_tilde\"):\n",
    "    y_tilde = tf.multiply(masks, spectrogram, name=\"y_tilde\") # broadcast along channel dimension\n",
    "\n",
    "# Loss function: L = Σ(||y_tilde_n - target_n||^2)\n",
    "with tf.name_scope(\"loss\"):\n",
    "    targets = tf.placeholder(tf.float32, \n",
    "                             shape=target_shape, \n",
    "                             name=\"target_sources\")\n",
    "    reduc_indices = [i for i in range(4) if i != channel_dim]\n",
    "    loss_n = tf.reduce_sum(tf.square(y_tilde - targets), axis=reduc_indices, name=\"loss_n\")\n",
    "    loss_total = tf.reduce_sum(loss_n, name=\"loss_total\")\n",
    "\n",
    "# Optimizer\n",
    "with tf.name_scope(\"train_step\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss_total)\n",
    "\n",
    "# Summaries\n",
    "saver = tf.train.Saver(max_to_keep=5)        \n",
    "graph = tf.get_default_graph()\n",
    "writer = tf.summary.FileWriter(results_dir, graph)\n",
    "loss_sum = []\n",
    "with tf.name_scope(\"summaries\"):\n",
    "    for i in range(num_sources):\n",
    "        loss_sum.append(tf.summary.scalar(\"loss_%d\" % (i+1), loss_n[i]))\n",
    "    loss_sum.append(tf.summary.scalar(\"loss_total\", loss_total))\n",
    "    loss_sum = tf.summary.merge(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_transpose(x,\n",
    "                     output_shape,\n",
    "                     kernel_size,\n",
    "                     stride=1,\n",
    "                     padding=\"VALID\",\n",
    "                     data_format=\"NCHW\",\n",
    "                     normalizer_fn=None,\n",
    "                     activation_fn=None,\n",
    "                     weights_initializer=\"random_normal\",\n",
    "                     biases_initializer=None,\n",
    "                     trainable=True,\n",
    "                     scope=\"CONV_T\"):\n",
    "    with tf.name_scope(scope):\n",
    "        x_shape = x.get_shape().as_list()\n",
    "        \n",
    "        # Create weights\n",
    "        W_init_type, W_init_params = _check_list(weights_initializer)\n",
    "        with tf.name_scope(W_init_type + \"_initializer\"):\n",
    "            if data_format == \"NHWC\":\n",
    "                input_channels = x_shape[3]\n",
    "                num_outputs = output_shape[3]\n",
    "            elif data_format == \"NCHW\":\n",
    "                input_channels = x_shape[1]\n",
    "                num_outputs = output_shape[1]\n",
    "            W_shape = kernel_size + [num_outputs, input_channels]\n",
    "            if W_init_type == \"xavier\": # based on output size\n",
    "                layer_shape = output_shape[1:]\n",
    "                n_out = tf.reduce_prod(layer_shape)\n",
    "                W_init_params = [n_out]\n",
    "            W_init = _get_variable_initializer(W_init_type,\n",
    "                                               W_shape,\n",
    "                                               *W_init_params)\n",
    "        W = tf.Variable(W_init, \n",
    "                        dtype=tf.float32, \n",
    "                        trainable=trainable, \n",
    "                        name=\"weights\")\n",
    "        \n",
    "\n",
    "        # Convolute input\n",
    "        stride_h, stride_w = _check_list(stride)\n",
    "        if isinstance(stride_w, list):\n",
    "            if len(stride_w) == 0:\n",
    "                stride_w = stride_h\n",
    "            else:\n",
    "                stride_w = stride_w[0]\n",
    "        if data_format == \"NHWC\":\n",
    "            strides = [1, stride_h, stride_w, 1]\n",
    "        elif data_format == \"NCHW\":\n",
    "            strides = [1, 1, stride_h, stride_w]\n",
    "        out = tf.nn.conv2d_transpose(x, \n",
    "                                     filter=W,\n",
    "                                     output_shape=output_shape,\n",
    "                                     strides=strides,\n",
    "                                     padding=padding,\n",
    "                                     data_format=data_format,\n",
    "                                     name=\"convolution_transpose\")\n",
    "        \n",
    "        # Apply normalization\n",
    "        if normalizer_fn is not None:\n",
    "            norm_type, norm_params = _check_list(normalizer_fn)\n",
    "            out = _apply_normalization(norm_type, \n",
    "                                       out, \n",
    "                                       *norm_params,\n",
    "                                       data_format=data_format)\n",
    "        \n",
    "        # Add biases\n",
    "        elif biases_initializer is not None:\n",
    "            b_init_type, b_init_params = _check_list(biases_initializer)\n",
    "            if data_format == \"NHWC\":\n",
    "                b_shape = [1, 1, 1, num_outputs]\n",
    "            elif data_format == \"NCHW\":\n",
    "                b_shape = [1, num_outputs, 1, 1]\n",
    "            b_init = _get_variable_initializer(b_init_type,\n",
    "                                               b_shape,\n",
    "                                               *b_init_params)\n",
    "            b = tf.Variable(b_init,\n",
    "                            dtype=tf.float32,\n",
    "                            trainable=trainable,\n",
    "                            name=\"biases\")\n",
    "            out = tf.add(out, b, name=\"BiasAdd\")\n",
    "\n",
    "        # Apply activation\n",
    "        if activation_fn is not None:\n",
    "            act_type, act_params = _check_list(activation_fn)\n",
    "            out = _apply_activation(act_type, out, *act_params)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
