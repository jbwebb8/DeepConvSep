{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Channel Source Separation\n",
    "Some ideas:\n",
    "- Deeper networks\n",
    "- Wider networks\n",
    "- Different conv filter sizes\n",
    "- Noisy inputs\n",
    "- Dropout\n",
    "\n",
    "Some notes about data preprocessing:\n",
    "In the original code, data is preprocessed from raw .wav files into numpy arrays containing the magnitude and phase spectrograms from the short time Fourier transfrom (STFT). The class `LargeDataset` in `dataset.py` handles the transformation and subsequent batch handling during network training. How does it work?\n",
    "\n",
    "1. The features (i.e. spectrograms) from the audio files are saved in a directory. If using the `compute_transform` function found in class `Transform` in `transform.py`, then the features for each audio file should be in this directory as:\n",
    "    - {filename}\\_\\_{m,p}\\_.data : numpy array containing the magnitude (m) or phase (p) spectrogram\n",
    "    - {filename}\\_\\_{m,p}\\_.shape : binary file containing shape of array\n",
    "2. The LargeDataset class is pointed to the feature directory via the `path_transform_in` argument in the constructor.\n",
    "3. It calls updatePath to update its list of .data files (self.file_list), which are all the .data files in the feature directory.\n",
    "4. updatePath also updates the cumulative number of points in the file list (`self.num_points`) and total points (`self.total_points`), where a point is a time window of size `time_context`. This is done via the getNum function, which essentially return the `np.floor(time_axis / time_context`, plus a term if using overlap:\n",
    "\n",
    "```python\n",
    "def getNum(self,id):\n",
    "        \"\"\"\n",
    "        For a single .data file computes the number of examples of size \\\"time_context\\\" that can be created\n",
    "        \"\"\"\n",
    "        shape = self.get_shape(os.path.join(self.path_transform_in[self.dirid[id]],self.file_list[id].replace('.data','.shape')))\n",
    "        time_axis = shape[1]\n",
    "        return np.maximum(1,int(np.floor((time_axis + (np.floor(float(time_axis)/self.time_context) * self.overlap))  / self.time_context)))\n",
    "```\n",
    "5. updatePath also updates the input and output feature sizes via the `getFeatureSize` function, which returns the number of features (self.input_size) and number of features * number of sources (self.output_size) for each .data file.\n",
    "6. Finally, updatePath calls `initBatches()`, which allocates memory needed for output. Several class variables are set:\n",
    "\n",
    "```python\n",
    "self.batch_size = np.minimum(self.batch_size,self.num_points[-1]) # size of each batch\n",
    "self.iteration_size = int(self.total_points / self.batch_size)    # number of batches in dataset\n",
    "self.batch_memory = np.minimum(self.batch_memory,self.iteration_size) # minimum number of batches to load into memory\n",
    "#...\n",
    "self.batch_inputs = np.zeros((self.batch_memory*self.batch_size,self.time_context,self.input_size), dtype=self.tensortype)\n",
    "        self.batch_outputs = np.zeros((self.batch_memory*self.batch_size,self.time_context,self.output_size), dtype=self.tensortype)\n",
    "```\n",
    "7. At this point, all files and directories are accounted for, but nothing has actually been  loaded into memory. `initBatches()` calls `loadBatches()`, which loads batches into `self.batch_inputs` and `self.batch_outputs` once the current store is exhausted, by itself calling `genBatches()`. First, `genBatches()` calls `getNextIndex()` to update class variables that set the time window for the next batch:\n",
    "\n",
    "```python\n",
    "def getNextIndex(self):\n",
    "    \"\"\"\n",
    "    Returns how many batches/sequences to load from each .data file\n",
    "    \"\"\"\n",
    "    # next time point = (# of loads into memory) * (# of time points per load)\n",
    "    target_value = (self.scratch_index+1)*(self.batch_memory*self.batch_size)\n",
    "    # next file index = right-sided search of files with cumulative sum = next time point\n",
    "    idx_target = np.searchsorted(self.num_points,target_value, side='right')\n",
    "    # End case: set idxend to the number of points in the last file, and nindex\n",
    "    # to the last file\n",
    "    if target_value>self.num_points[-1] or idx_target>=len(self.num_points):\n",
    "        idx_target = idx_target - 2\n",
    "        target_value = self.num_points[idx_target]\n",
    "        self.idxend = self.num_points[idx_target] - self.num_points[idx_target-1]\n",
    "        self.nindex = idx_target\n",
    "    # Otherwise, set idxend to number of points after file ending just prior to target\n",
    "    # time point, and nindex to that file\n",
    "    else:\n",
    "        while target_value<=self.num_points[idx_target]:\n",
    "            idx_target = idx_target - 1\n",
    "        self.idxend = target_value - self.num_points[idx_target]\n",
    "        self.nindex = idx_target\n",
    "```\n",
    "8. Next, `genBatches()` decides how much to load from how many files in order to produce batches of the desired length. It utilizes the `loadFile()` function to load .data files into memory between indices `idxbegin` and `idxend`.  As seen in the `loadInputOutput()` helper function, the .data file `file` contains the input, or unseparated STFT, in `allmixinput = file[0]` and the output, or source separated STFTs, in `allmixoutput = file[1:]`. The STFTs are scaled by a (log) scale factor:\n",
    "\n",
    "```python\n",
    "#apply a scaled log10(1+value) function to make sure larger values are eliminated\n",
    "#bach10 training: mult_factor_in = mult_factor_out = 0.3 (0.2 for testing)\n",
    "#                 log_in = log_out = False\n",
    "if self.log_in==True:\n",
    "    allmixinput = self.mult_factor_in*np.log10(1.0+allmixinput)\n",
    "else:\n",
    "    allmixinput = self.mult_factor_in*allmixinput\n",
    "if self.log_out==True:\n",
    "    allmixoutput = self.mult_factor_out*np.log10(1.0+allmixoutput)\n",
    "else:\n",
    "    allmixoutput = self.mult_factor_out*allmixoutput\n",
    "```\n",
    "9. The inputs and outputs in `loadFile()` are originally set via `loadOutput()` to:\n",
    "\n",
    "```python\n",
    "size = idxend - idxbegin\n",
    "inp = np.zeros((size, self.time_context, self.input_size), dtype=self.tensortype)\n",
    "out = np.zeros((size, self.time_context, self.output_size), dtype=self.tensortype)\n",
    "```\n",
    "10. If the file size is smaller than `time_context`, then the first part of `inputs` and `outputs` are taken from the file:\n",
    "\n",
    "```python\n",
    "if self.time_context > allmixinput.shape[1]:\n",
    "    inputs[0,:allmixinput.shape[1],:] = allmixinput[0]\n",
    "    outputs[0, :allmixoutput.shape[1], :allmixoutput.shape[-1]] = allmixoutput[0]\n",
    "    # ...\n",
    "    # concatenate features from rest of sources to third (feature) dimension\n",
    "    for j in range(1,self.nsources):\n",
    "        outputs[0, :allmixoutput.shape[1], j*allmixoutput.shape[-1]:(j+1)*allmixoutput.shape[-1]] = allmixoutput[j]\n",
    "```\n",
    "10. Otherwise, samples of size `time_context` are taken from the file along the time dimension until the target number of loaded samples is satisfied:\n",
    "\n",
    "```python\n",
    "else:\n",
    "    while (start + self.time_context) < allmixinput.shape[1]:\n",
    "        if i>=idxbegin and i<idxend:\n",
    "            # separate variables names for memory clearing\n",
    "            allminput = allmixinput[:,start:start+self.time_context,:] #truncate on time axis so it would match the actual context\n",
    "            allmoutput = allmixoutput[:,start:start+self.time_context,:]\n",
    "            inputs[i-idxbegin] = allminput[0]\n",
    "            outputs[i-idxbegin, :, :allmoutput.shape[-1]] = allmoutput[0]\n",
    "            # ...\n",
    "            # concatenate features from rest of sources to third (feature) dimension\n",
    "            for j in range(1,self.nsources):\n",
    "                outputs[i-idxbegin,:, j*allmoutput.shape[-1]:(j+1)*allmoutput.shape[-1]] = allmoutput[j,:,:]\n",
    "            # ...\n",
    "\n",
    "        i = i + 1\n",
    "        start = start - self.overlap + self.time_context\n",
    "        #clear memory\n",
    "        allminput=None\n",
    "        allmoutput=None\n",
    "```\n",
    "11. `loadFile()` returns a dictionary of input and output (and other) values to `genBatches()`. After smartly loading from the correct number of files in sequence to fill `self.batch_inputs` and `self.batch_outputs`, the batches are shuffled via `shuffleBatches()`. Finally, class variables are incremented accordingly in anticipation of the next call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "Something weird is happening where the GPU is not being recognized in the `elec576` conda env. Just stick with the `vizdoom` env for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If using one or multiple GPUs\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os, errno\n",
    "import re\n",
    "from time import time, sleep\n",
    "#from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_directory(f):\n",
    "    \"\"\"Makes directory if does not already exist\"\"\"\n",
    "    try:\n",
    "        os.makedirs(f)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _check_list(arg):\n",
    "    if isinstance(arg, list):\n",
    "        try:\n",
    "            return arg[0], arg[1:]\n",
    "        except IndexError:\n",
    "            return arg[0], []\n",
    "    else:\n",
    "        return arg, []\n",
    "\n",
    "def _get_variable_initializer(init_type, var_shape, *args):\n",
    "    if init_type == \"random_normal\":\n",
    "        mean = float(args[0])\n",
    "        stddev = float(args[1])\n",
    "        return tf.random_normal(var_shape, mean=mean, stddev=stddev)\n",
    "    elif init_type == \"truncated_normal\":\n",
    "        mean = float(args[0])\n",
    "        stddev = float(args[1])\n",
    "        return tf.truncated_normal(var_shape, mean=mean, stddev=stddev)\n",
    "    elif init_type == \"constant\":\n",
    "        c = args[0]\n",
    "        return tf.constant(c, dtype=tf.float32, shape=var_shape)\n",
    "    elif init_type == \"xavier\":\n",
    "        n_in = tf.cast(args[0], tf.float32)\n",
    "        return tf.div(tf.random_normal(var_shape), tf.sqrt(n_in))\n",
    "    else:\n",
    "        raise ValueError(\"Variable initializer \\\"\" + init_type + \"\\\" not supported.\")\n",
    "\n",
    "def _apply_normalization(norm_type, x, *args, **kwargs):\n",
    "    if norm_type == \"batch_norm\":\n",
    "        return batch_norm(x, *args, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Normalization type \\\"\" + norm_type + \"\\\" not supported.\")\n",
    "\n",
    "def _apply_activation(activation_type, x, *args):\n",
    "    if activation_type.lower() == \"relu\":\n",
    "        return tf.nn.relu(x, name=\"Relu\")\n",
    "    elif activation_type.lower() == \"leaky_relu\":\n",
    "        return tf.maximum(x, 0.1 * x, name=\"Leaky_Relu\")\n",
    "    elif activation_type.lower() == \"softmax\":\n",
    "        return tf.nn.softmax(x)\n",
    "    elif activation_type.lower() == \"none\":\n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError(\"Activation type \\\"\" + activation_type + \"\\\" not supported.\")\n",
    "        \n",
    "def conv2d(input_layer,\n",
    "           num_outputs,\n",
    "           kernel_size,\n",
    "           stride=1,\n",
    "           padding=\"VALID\",\n",
    "           data_format=\"NCHW\",\n",
    "           normalizer_fn=None,\n",
    "           activation_fn=None,\n",
    "           weights_initializer=\"random_normal\",\n",
    "           biases_initializer=None,\n",
    "           trainable=True,\n",
    "           scope=\"CONV\"):\n",
    "    with tf.name_scope(scope):\n",
    "        input_shape = input_layer.get_shape().as_list()\n",
    "        \n",
    "        # Create weights\n",
    "        W_init_type, W_init_params = _check_list(weights_initializer)\n",
    "        with tf.name_scope(W_init_type + \"_initializer\"):\n",
    "            if data_format == \"NHWC\":\n",
    "                input_channels = input_shape[3]\n",
    "            elif data_format == \"NCHW\":\n",
    "                input_channels = input_shape[1]\n",
    "            W_shape = kernel_size + [input_channels, num_outputs]\n",
    "            if W_init_type == \"xavier\":\n",
    "                layer_shape = input_shape[1:]\n",
    "                n_in = tf.reduce_prod(layer_shape)\n",
    "                W_init_params = [n_in] \n",
    "            W_init = _get_variable_initializer(W_init_type,\n",
    "                                                W_shape,\n",
    "                                                *W_init_params)\n",
    "        W = tf.Variable(W_init, \n",
    "                        dtype=tf.float32, \n",
    "                        trainable=trainable, \n",
    "                        name=\"weights\")\n",
    "        \n",
    "\n",
    "        # Convolute input\n",
    "        stride_h, stride_w = _check_list(stride)\n",
    "        if isinstance(stride_w, list):\n",
    "            if len(stride_w) == 0:\n",
    "                stride_w = stride_h\n",
    "            else:\n",
    "                stride_w = stride_w[0]\n",
    "        if data_format == \"NHWC\":\n",
    "            strides = [1, stride_h, stride_w, 1]\n",
    "        elif data_format == \"NCHW\":\n",
    "            strides = [1, 1, stride_h, stride_w]\n",
    "        out = tf.nn.conv2d(input_layer, \n",
    "                            filter=W,\n",
    "                            strides=strides,\n",
    "                            padding=padding,\n",
    "                            data_format=data_format,\n",
    "                            name=\"convolution\")\n",
    "        \n",
    "        # Apply normalization\n",
    "        if normalizer_fn is not None:\n",
    "            norm_type, norm_params = _check_list(normalizer_fn)\n",
    "            out = _apply_normalization(norm_type, \n",
    "                                       out, \n",
    "                                       *norm_params,\n",
    "                                       data_format=data_format)\n",
    "        \n",
    "        # Add biases\n",
    "        elif biases_initializer is not None:\n",
    "            b_init_type, b_init_params = _check_list(biases_initializer)\n",
    "            if data_format == \"NHWC\":\n",
    "                b_shape = [1, 1, 1, num_outputs]\n",
    "            elif data_format == \"NCHW\":\n",
    "                b_shape = [1, num_outputs, 1, 1]\n",
    "            b_init = _get_variable_initializer(b_init_type,\n",
    "                                               b_shape,\n",
    "                                               *b_init_params)\n",
    "            b = tf.Variable(b_init,\n",
    "                            dtype=tf.float32,\n",
    "                            trainable=trainable,\n",
    "                            name=\"biases\")\n",
    "            out = tf.add(out, b, name=\"BiasAdd\")\n",
    "\n",
    "        # Apply activation\n",
    "        if activation_fn is not None:\n",
    "            act_type, act_params = _check_list(activation_fn)\n",
    "            out = _apply_activation(act_type, out, *act_params)\n",
    "\n",
    "        return out\n",
    "\n",
    "def conv2d_transpose(x,\n",
    "                     output_shape,\n",
    "                     kernel_size,\n",
    "                     stride=1,\n",
    "                     padding=\"VALID\",\n",
    "                     data_format=\"NCHW\",\n",
    "                     normalizer_fn=None,\n",
    "                     activation_fn=None,\n",
    "                     weights_initializer=\"random_normal\",\n",
    "                     biases_initializer=None,\n",
    "                     trainable=True,\n",
    "                     scope=\"CONV_T\"):\n",
    "    with tf.name_scope(scope):\n",
    "        x_shape = x.get_shape().as_list()\n",
    "        \n",
    "        # Create weights\n",
    "        W_init_type, W_init_params = _check_list(weights_initializer)\n",
    "        with tf.name_scope(W_init_type + \"_initializer\"):\n",
    "            if data_format == \"NHWC\":\n",
    "                input_channels = x_shape[3]\n",
    "                num_outputs = output_shape[3]\n",
    "            elif data_format == \"NCHW\":\n",
    "                input_channels = x_shape[1]\n",
    "                num_outputs = output_shape[1]\n",
    "            W_shape = kernel_size + [num_outputs, input_channels]\n",
    "            if W_init_type == \"xavier\": # based on output size\n",
    "                layer_shape = output_shape[1:]\n",
    "                n_out = tf.reduce_prod(layer_shape)\n",
    "                W_init_params = [n_out]\n",
    "            W_init = _get_variable_initializer(W_init_type,\n",
    "                                               W_shape,\n",
    "                                               *W_init_params)\n",
    "        W = tf.Variable(W_init, \n",
    "                        dtype=tf.float32, \n",
    "                        trainable=trainable, \n",
    "                        name=\"weights\")\n",
    "        \n",
    "\n",
    "        # Convolute input\n",
    "        stride_h, stride_w = _check_list(stride)\n",
    "        if isinstance(stride_w, list):\n",
    "            if len(stride_w) == 0:\n",
    "                stride_w = stride_h\n",
    "            else:\n",
    "                stride_w = stride_w[0]\n",
    "        if data_format == \"NHWC\":\n",
    "            strides = [1, stride_h, stride_w, 1]\n",
    "        elif data_format == \"NCHW\":\n",
    "            strides = [1, 1, stride_h, stride_w]\n",
    "        out = tf.nn.conv2d_transpose(x, \n",
    "                                     filter=W,\n",
    "                                     output_shape=output_shape,\n",
    "                                     strides=strides,\n",
    "                                     padding=padding,\n",
    "                                     data_format=data_format,\n",
    "                                     name=\"convolution_transpose\")\n",
    "        \n",
    "        # Apply normalization\n",
    "        if normalizer_fn is not None:\n",
    "            norm_type, norm_params = _check_list(normalizer_fn)\n",
    "            out = _apply_normalization(norm_type, \n",
    "                                       out, \n",
    "                                       *norm_params,\n",
    "                                       data_format=data_format)\n",
    "        \n",
    "        # Add biases\n",
    "        elif biases_initializer is not None:\n",
    "            b_init_type, b_init_params = _check_list(biases_initializer)\n",
    "            if data_format == \"NHWC\":\n",
    "                b_shape = [1, 1, 1, num_outputs]\n",
    "            elif data_format == \"NCHW\":\n",
    "                b_shape = [1, num_outputs, 1, 1]\n",
    "            b_init = _get_variable_initializer(b_init_type,\n",
    "                                               b_shape,\n",
    "                                               *b_init_params)\n",
    "            b = tf.Variable(b_init,\n",
    "                            dtype=tf.float32,\n",
    "                            trainable=trainable,\n",
    "                            name=\"biases\")\n",
    "            out = tf.add(out, b, name=\"BiasAdd\")\n",
    "\n",
    "        # Apply activation\n",
    "        if activation_fn is not None:\n",
    "            act_type, act_params = _check_list(activation_fn)\n",
    "            out = _apply_activation(act_type, out, *act_params)\n",
    "\n",
    "        return out\n",
    "    \n",
    "def flatten(input_layer, \n",
    "            data_format=\"NCHW\",\n",
    "            scope=\"FLAT\"):\n",
    "    with tf.name_scope(scope):\n",
    "        # Grab runtime values to determine number of elements\n",
    "        input_shape = tf.shape(input_layer)\n",
    "        input_ndims = input_layer.get_shape().ndims\n",
    "        batch_size = tf.slice(input_shape, [0], [1])\n",
    "        layer_shape = tf.slice(input_shape, [1], [input_ndims-1])\n",
    "        num_neurons = tf.expand_dims(tf.reduce_prod(layer_shape), 0)\n",
    "        flattened_shape = tf.concat([batch_size, num_neurons], 0)\n",
    "        if data_format == \"NHWC\":\n",
    "            input_layer = tf.transpose(input_layer, perm=[0, 3, 1, 2])\n",
    "        flat = tf.reshape(input_layer, flattened_shape)\n",
    "        \n",
    "        # Attempt to set values during graph building\n",
    "        input_shape = input_layer.get_shape().as_list()\n",
    "        batch_size, layer_shape = input_shape[0], input_shape[1:]\n",
    "        if all(layer_shape): # None not present\n",
    "            num_neurons = 1\n",
    "            for dim in layer_shape:\n",
    "                num_neurons *= dim\n",
    "            flat.set_shape([batch_size, num_neurons])\n",
    "        else: # None present\n",
    "            flat.set_shape([batch_size, None])\n",
    "        return flat\n",
    "\n",
    "def fully_connected(input_layer,\n",
    "                    num_outputs,\n",
    "                    normalizer_fn=None,\n",
    "                    activation_fn=None,\n",
    "                    weights_initializer=\"random_normal\",\n",
    "                    biases_initializer=None,\n",
    "                    trainable=True,\n",
    "                    scope=\"FC\"):\n",
    "    with tf.name_scope(scope):\n",
    "        input_shape = input_layer.get_shape().as_list()\n",
    "        \n",
    "        # Create weights\n",
    "        W_init_type, W_init_params = _check_list(weights_initializer)\n",
    "        with tf.name_scope(W_init_type + \"_initializer\"):\n",
    "            W_shape = [input_shape[1], num_outputs]\n",
    "            if W_init_type == \"xavier\":\n",
    "                layer_shape = input_shape[1]\n",
    "                n_in = tf.reduce_prod(layer_shape)\n",
    "                W_init_params = [n_in]\n",
    "            W_init = _get_variable_initializer(W_init_type,\n",
    "                                            W_shape,\n",
    "                                            *W_init_params)\n",
    "        W = tf.Variable(W_init,\n",
    "                        dtype=tf.float32, \n",
    "                        trainable=trainable, \n",
    "                        name=\"weights\")\n",
    "        \n",
    "        # Multiply inputs by weights\n",
    "        out = tf.matmul(input_layer, W)\n",
    "\n",
    "        # Apply normalization\n",
    "        if normalizer_fn is not None:\n",
    "            norm_type, norm_params = _check_list(normalizer_fn)\n",
    "            out = _apply_normalization(norm_type, \n",
    "                                       out, \n",
    "                                       *norm_params,\n",
    "                                       data_format=None)\n",
    "\n",
    "        # Add biases\n",
    "        elif biases_initializer is not None:\n",
    "            b_init_type, b_init_params = _check_list(biases_initializer)\n",
    "            b_shape = [num_outputs]\n",
    "            b_init = _get_variable_initializer(b_init_type,\n",
    "                                               b_shape,\n",
    "                                               *b_init_params)\n",
    "            b = tf.Variable(b_init,\n",
    "                            dtype=tf.float32,\n",
    "                            trainable=trainable,\n",
    "                            name=\"biases\")\n",
    "            out = tf.add(out, b, name=\"BiasAdd\")\n",
    "       \n",
    "        # Apply activation\n",
    "        if activation_fn is not None:\n",
    "            act_type, act_params = _check_list(activation_fn)\n",
    "            out = _apply_activation(act_type, out, *act_params)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataset handling\n",
    "The training data will be fed in a given amount of files at a time specified by number of mixture-source feature file pairs.\n",
    "There are two approaches to using mem map, and unfortunately neither seems to completely avoid moving large amounts of data upon initialization:\n",
    "1. Use `np.memmap` following instructions from [this stackoverflow question](https://stackoverflow.com/questions/13780907/is-it-possible-to-np-concatenate-memory-mapped-files). The third (placeholder) array ends up writing all data to the file of the initial array. This in essence creates a single, giant array that contains the concatenated information from all songs along the time axis. While this would work, it doubles the amount of space on the hard drive if not deleted after training, and takes a long time (~30 min) to initialize if deleted after every use.\n",
    "2. Use the `mmap_mode` arg in `np.load`. While this works for single files, any results of manipulation of the arrays (e.g. `np.concatenate` along time axis) are loaded into memory, which defeats the purpose of using mmap in the first place.\n",
    "\n",
    "I think the best compromise is to use `np.load(filename, mmap_mode='r')` to point to the arrays and grab shapes initially, which can be used to track the global time point. Then some number of files can be loaded at a time that correspond to the number of time points to load at a time. Class variables can track the global time point, time point within loaded files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 load_by_file=False,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal'],\n",
    "                 data_format=\"NHWC\",\n",
    "                 shuffle=True,\n",
    "                 verbose=True):\n",
    "        # Grab arguments\n",
    "        self.batch_size = batch_size\n",
    "        self.time_context = time_context\n",
    "        self.num_sources = len(sources)\n",
    "        self.data_format = data_format\n",
    "        self.shuffle = shuffle\n",
    "        self.verbose = verbose\n",
    "        self.load_by_file = load_by_file\n",
    "        \n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) \n",
    "                                   for f in os.listdir(input_dir) if \"mag\" in f])\n",
    "        target_files = sorted([os.path.join(target_dir, f) \n",
    "                               for f in os.listdir(target_dir) if \"mag\" in f])\n",
    "        self.source_files = [] # [source_id][t]\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "        \n",
    "        # Read mem maps of data files\n",
    "        self.inputs = []\n",
    "        self.sources = [] # [t][source_id]\n",
    "        self.shapes = []\n",
    "        shapes_ = [] # placeholder to ensure all associated shapes equal\n",
    "        for i in range(len(self.input_files)):\n",
    "            if verbose:\n",
    "                print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            \n",
    "            # Add mem map of mixture file\n",
    "            f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            self.inputs.append(f_in)\n",
    "            \n",
    "            # Add mem maps of source files\n",
    "            f_s = [np.load(self.source_files[j][i], mmap_mode='r') \n",
    "                   for j in range(len(sources))]\n",
    "            self.sources.append(f_s)\n",
    "            \n",
    "            # Get shapes\n",
    "            self.shapes.append(f_in.shape)\n",
    "            shapes_.append([f.shape for f in f_s])\n",
    "        \n",
    "        # Set class variables\n",
    "        self.shapes = np.asarray(self.shapes)\n",
    "        self.t_total = np.sum(self.shapes[:, 0])\n",
    "        self.feat_size = self.shapes[0, 1]\n",
    "        \n",
    "        # Check that shapes [index, ch, shape] are equal for each time point\n",
    "        shapes_ = np.concatenate([self.shapes[:, np.newaxis, :], np.asarray(shapes_)], axis=1)\n",
    "        if not (shapes_[:, :, 0].T == shapes_[:, 0, 0]).all():\n",
    "            raise ValueError(\"All spectrograms must be of same length.\")\n",
    "        if not (shapes_[:, :, 1].T == shapes_[:, 0, 1]).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        shapes_ = None # release from memory\n",
    "            \n",
    "        # Set variables to track time position\n",
    "        self.t_c = np.cumsum(self.shapes[:, 0])\n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_next = False # if True, load next batch of files\n",
    "        self.inputs_, self.sources_ = [], []\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        # Get indices of files corresponding to next mem_len time points or next file\n",
    "        t_start = self.t\n",
    "        t_end = self.t + self.mem_len\n",
    "        idx_start = np.searchsorted(self.t_c, t_start, side='right')\n",
    "        if self.load_by_file:\n",
    "            idx_end = idx_start + 1\n",
    "        else:\n",
    "            idx_end = np.searchsorted(self.t_c, t_end, side='right')\n",
    "        if idx_end - idx_start < 1:\n",
    "            raise SyntaxError(\"Unable to load next file. Check mem_len (must be greater than file size)\")\n",
    "        if self.verbose:\n",
    "            print(\"Loading files %d to %d of %d into memory...\" % (idx_start+1, idx_end, len(self.inputs)))\n",
    "        \n",
    "        # Clear memory\n",
    "        del self.sources_\n",
    "        del self.inputs_\n",
    "        \n",
    "        # Load from mem maps of files into shape [time, features, [num_sources]]:\n",
    "        # from inputs\n",
    "        f_in = [self.inputs[t] for t in range(idx_start, idx_end)] # get list of next files\n",
    "        #self.inputs_ = np.concatenate(f_in, axis=0) # loads into memory but SLOW\n",
    "        t_shape = np.sum(self.shapes[idx_start:idx_end, 0]) # grab total shape ahead of time (much faster)\n",
    "        self.inputs_ = np.zeros([t_shape, self.feat_size]) # set total memory block\n",
    "        t_idx = 0 # running time index\n",
    "        for i, f in enumerate(f_in):\n",
    "            self.inputs_[t_idx:t_idx+self.shapes[idx_start+i, 0]] = f\n",
    "            t_idx += self.shapes[idx_start+i, 0]\n",
    "        \n",
    "        # from sources\n",
    "        f_s = [np.asarray(self.sources[t]) for t in range(idx_start, idx_end)]\n",
    "        #self.sources_ = np.transpose(np.concatenate(f_s, axis=1), axes=[1, 2, 0]) # loads into memory\n",
    "        self.sources_ = np.zeros([t_shape, self.feat_size, self.num_sources])\n",
    "        t_idx = 0\n",
    "        for i, f in enumerate(f_s):\n",
    "            self.sources_[t_idx:t_idx+self.shapes[idx_start+i, 0]] = np.transpose(f, [1, 2, 0])\n",
    "            t_idx += self.shapes[idx_start+i, 0]\n",
    "        \n",
    "        # Shuffle chunks of size time context\n",
    "        if self.shuffle:\n",
    "            self.shuffle_data()\n",
    "        \n",
    "        # Reset counter\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def shuffle_data(self):\n",
    "        # This increases memory requirements by ~50% (copying self.inputs_ or self.sources_ \n",
    "        # during reshape operations. I don't know of a way to reshape in place without \n",
    "        # copying the array, which is affirmed in the numpy docs.\n",
    "        if self.verbose:\n",
    "            print(\"Shuffling data...\")\n",
    "        \n",
    "        # Reshape data into chunks of size time_context and save ends\n",
    "        concat = False\n",
    "        if self.inputs_.shape[0] % self.time_context != 0:\n",
    "            end_idx = self.inputs_.shape[0] // self.time_context * self.time_context\n",
    "            end_inputs = self.inputs_[end_idx:]\n",
    "            self.inputs_ = self.inputs_[:end_idx]\n",
    "            end_sources = self.sources_[end_idx:]\n",
    "            self.sources_ = self.sources_[:end_idx]\n",
    "            concat = True\n",
    "        self.inputs_ = self.inputs_.reshape([-1, self.time_context, self.feat_size])\n",
    "        self.sources_ = self.sources_.reshape([-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        \n",
    "        # Shuffle inputs and sources in unison\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(self.inputs_)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(self.sources_)\n",
    "        \n",
    "        # Reshape data into original shape [time, features, [num_sources]]\n",
    "        self.inputs_ = self.inputs_.reshape([-1, self.feat_size])\n",
    "        self.sources_ = self.sources_.reshape([-1, self.feat_size, self.num_sources])\n",
    "        if concat:\n",
    "            self.inputs_ = np.concatenate([self.inputs_, end_inputs])\n",
    "            self.sources_ = np.concatenate([self.sources_, end_sources])\n",
    "    \n",
    "    def reset_database(self):\n",
    "        if self.verbose:\n",
    "            print(\"Resetting database...\")\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Load memory if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        elif self.load_next:\n",
    "            self.load_memory()\n",
    "        \n",
    "        # Determine batch length and set loading bools for next batch\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        rem = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        if self.t + batch_len > self.t_total: # reach end of all data\n",
    "            batch_len = (self.t_total - self.t) // self.time_context * self.time_context\n",
    "            rem = (self.t_total - self.t) % self.time_context\n",
    "            self.reset = True\n",
    "        elif self.t_ + batch_len > self.inputs_.shape[0]: # reach end of loaded data\n",
    "            batch_len = (self.inputs_.shape[0] - self.t_) // self.time_context * self.time_context\n",
    "            rem = (self.inputs_.shape[0] - self.t_) % self.time_context\n",
    "            self.load_next = True\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[self.t_:self.t_+batch_len],\n",
    "                                  [-1, self.time_context, self.feat_size, 1])\n",
    "        sources_batch = np.reshape(self.sources_[self.t_:self.t_+batch_len],\n",
    "                                    [-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        if self.data_format == \"NCHW\":\n",
    "            inputs_batch = np.transpose(inputs_batch, axes=[0, 3, 1, 2])\n",
    "            sources_batch = np.transpose(sources_batch, axes=[0, 3, 1, 2])\n",
    "        \n",
    "        # Increment counters\n",
    "        self.t_ += batch_len + rem \n",
    "        self.t  += batch_len + rem\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return ds.reset\n",
    "    \n",
    "    def remaining_batches(self):\n",
    "        return math.ceil((self.inputs_.shape[0] - self.t_) \n",
    "                         / (self.batch_size * self.time_context))\n",
    "    \n",
    "    def remaining_files(self):\n",
    "        return len(self.inputs) - np.searchsorted(self.t_c, self.t, side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 results_dir,\n",
    "                 params_file=None,\n",
    "                 data_format=\"NCHW\",\n",
    "                 time_context=30,\n",
    "                 feat_size=513,\n",
    "                 num_sources=4,\n",
    "                 alpha=0.001,\n",
    "                 verbose=True,\n",
    "                 train_mode=True,\n",
    "                 scope=\"\"):\n",
    "        # Get args\n",
    "        self.results_dir = results_dir\n",
    "        self.data_format = data_format\n",
    "        self.time_context = time_context\n",
    "        self.feat_size = feat_size\n",
    "        self.num_sources = num_sources\n",
    "        self.alpha = alpha\n",
    "        self.scope = scope\n",
    "        self.verbose = verbose\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        # Build graph\n",
    "        tf.reset_default_graph()\n",
    "        with tf.name_scope(scope):\n",
    "            self.build_graph()\n",
    "        self.sess = tf.Session()\n",
    "        if params_file is not None:\n",
    "            self.load_model(params_file)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.global_step = 0\n",
    "        \n",
    "\n",
    "    def build_graph(self):\n",
    "        eps = 1e-18 # numerical stability\n",
    "        \n",
    "        # Data formatting\n",
    "        if self.verbose:\n",
    "            print(\"Building input...\")\n",
    "        if self.data_format == \"NHWC\":\n",
    "            input_shape = [None, self.time_context, self.feat_size, 1]\n",
    "            target_shape = [None, self.time_context, self.feat_size, self.num_sources]\n",
    "            channel_dim = 3\n",
    "        elif self.data_format == \"NCHW\":\n",
    "            input_shape = [None, 1, self.time_context, self.feat_size]\n",
    "            target_shape = [None, self.num_sources, self.time_context, self.feat_size]\n",
    "            channel_dim = 1\n",
    "        else:\n",
    "            raise ValueError(\"Unknown data format \\\"\" + self.data_format + \"\\\"\")\n",
    "        self.spectrogram = tf.placeholder(tf.float32, \n",
    "                                     shape=input_shape, \n",
    "                                     name=\"magnitude_spectrogram\")\n",
    "        \n",
    "        # Encoder\n",
    "        if self.verbose:\n",
    "            print(\"Building encoder...\")\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = conv2d(self.spectrogram,\n",
    "                       num_outputs=30,\n",
    "                       kernel_size=[1, 30],\n",
    "                       stride=[1, 4],\n",
    "                       padding=\"VALID\",\n",
    "                       data_format=self.data_format,\n",
    "                       weights_initializer=\"xavier\",\n",
    "                       biases_initializer=[\"constant\", 0.0],\n",
    "                       scope=\"CONV_1\")\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = conv2d(self.conv1,\n",
    "                       num_outputs=30,\n",
    "                       kernel_size=[int(2*self.time_context/3), 1],\n",
    "                       stride=[1, 1],\n",
    "                       padding=\"VALID\",\n",
    "                       data_format=self.data_format,\n",
    "                       weights_initializer=\"xavier\",\n",
    "                       biases_initializer=[\"constant\", 0.0],\n",
    "                       scope=\"CONV_2\")\n",
    "        self.conv2_flat = flatten(self.conv2,\n",
    "                             data_format=self.data_format,\n",
    "                             scope=\"CONV_2_FLAT\")\n",
    "\n",
    "        # Fully-connected layer 1 (encoding)\n",
    "        self.fc1 = fully_connected(self.conv2_flat,\n",
    "                              num_outputs=256,\n",
    "                              activation_fn=\"relu\",\n",
    "                              weights_initializer=\"xavier\",\n",
    "                              biases_initializer=[\"constant\", 0.0],\n",
    "                              scope=\"FC_1\")\n",
    "        # Decoder\n",
    "        if self.verbose:\n",
    "            print(\"Building decoder...\")\n",
    "            \n",
    "        # Get shapes for building decoding layers\n",
    "        batch_size = tf.shape(self.spectrogram)[0]\n",
    "        conv1_shape = self.conv1.get_shape().as_list()\n",
    "        conv2_shape = self.conv2.get_shape().as_list()\n",
    "        conv2_size = conv2_shape[1] * conv2_shape[2] * conv2_shape[3]\n",
    "\n",
    "        # Build decoder for each source\n",
    "        self.fc2, self.convt1, self.convt2 = [], [], []\n",
    "        for i in range(self.num_sources):\n",
    "            # Fully-connected layer 2 (decoding)\n",
    "            fc2_i = fully_connected(self.fc1,\n",
    "                                    num_outputs=conv2_size,\n",
    "                                    activation_fn=\"relu\",\n",
    "                                    weights_initializer=\"xavier\",\n",
    "                                    biases_initializer=[\"constant\", 0.0],\n",
    "                                    scope=\"FC_2_%d\" % (i+1))\n",
    "            self.fc2.append(fc2_i)\n",
    "\n",
    "            # Convolutional transpose layer 1\n",
    "            # Side note: tf.reshape() can infer size of one dimension given rest, so -1 okay\n",
    "            #            tf.nn.conv2d_transpose() must know exact dimensions, but batch size can\n",
    "            #                be inferred at runtime using tf.shape()\n",
    "            fc2_i = tf.reshape(fc2_i, [-1] + conv2_shape[1:])\n",
    "            convt1_i = conv2d_transpose(fc2_i,\n",
    "                                        output_shape=[batch_size] + conv1_shape[1:],\n",
    "                                        kernel_size=[int(2*self.time_context/3), 1],\n",
    "                                        stride=[1, 1],\n",
    "                                        padding=\"VALID\",\n",
    "                                        data_format=self.data_format,\n",
    "                                        weights_initializer=\"xavier\",\n",
    "                                        biases_initializer=[\"constant\", 0.0],\n",
    "                                        scope=\"CONVT_1_%d\" % (i+1))\n",
    "            self.convt1.append(convt1_i)\n",
    "\n",
    "            # Convolutional transpose layer 2\n",
    "            convt2_i = conv2d_transpose(convt1_i,\n",
    "                                        output_shape=[batch_size] + input_shape[1:],\n",
    "                                        kernel_size=[1, 30],\n",
    "                                        stride=[1, 4],\n",
    "                                        padding=\"VALID\",\n",
    "                                        data_format=self.data_format,\n",
    "                                        weights_initializer=\"xavier\",\n",
    "                                        biases_initializer=[\"constant\", 0.0],\n",
    "                                        scope=\"CONVT_2_%d\" % (i+1))\n",
    "            self.convt2.append(convt2_i)\n",
    "        \n",
    "        # Output\n",
    "        if self.verbose:\n",
    "            print(\"Building output...\")\n",
    "            \n",
    "        # Output layer\n",
    "        with tf.name_scope(\"y_hat\"):\n",
    "            convt2_all = tf.concat(self.convt2, axis=channel_dim)\n",
    "            b = tf.Variable(tf.constant(0.0, shape=[1, 1, 1, 1]),\n",
    "                            dtype=tf.float32,\n",
    "                            name=\"bias\")\n",
    "            self.y_hat = tf.maximum(tf.add(convt2_all, b), 0, name=\"y_hat\")\n",
    "\n",
    "        # Masks: m_n(f) = |y_hat_n(f)| / Σ(|y_hat_n'(f)|)\n",
    "        with tf.name_scope(\"masks\"):\n",
    "            rand = tf.random_uniform([batch_size] + input_shape[1:])\n",
    "            den = tf.reduce_sum(self.y_hat, axis=channel_dim, keep_dims=True) + (eps * rand)\n",
    "            self.masks = tf.div(self.y_hat, den, name=\"masks\") # broadcast along channel dimension\n",
    "\n",
    "        # Source signals: y_tilde_n(f) = m_n(f) * x(f), \n",
    "        # where x(f) is the spectrogram of the input mixture signal\n",
    "        with tf.name_scope(\"y_tilde\"):\n",
    "            self.y_tilde = tf.multiply(self.masks, self.spectrogram, name=\"y_tilde\") # broadcast along channel dimension\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Building losses and summaries...\")\n",
    "            \n",
    "        # Loss function: L = 1/N * Σ(||y_tilde_n - target_n||^2)\n",
    "        # Changed from total to mean loss to account for different feature sizes\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.targets = tf.placeholder(tf.float32, \n",
    "                                     shape=target_shape, \n",
    "                                     name=\"target_sources\")\n",
    "            reduc_indices = [i for i in range(4) if i != channel_dim]\n",
    "            self.loss_n = tf.reduce_mean(tf.square(self.y_tilde - self.targets), \n",
    "                                        axis=reduc_indices, \n",
    "                                        name=\"loss_n\")\n",
    "            self.loss_total = tf.reduce_mean(self.loss_n, name=\"loss_total\")\n",
    "        \n",
    "        # Optimizer\n",
    "        with tf.name_scope(\"train_step\"):\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.alpha)\n",
    "            self.train_step = self.optimizer.minimize(self.loss_total)\n",
    "\n",
    "        # Summaries\n",
    "        self.saver = tf.train.Saver(max_to_keep=1)        \n",
    "        self.graph = tf.get_default_graph()\n",
    "        self.writer = tf.summary.FileWriter(self.results_dir, self.graph)\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            # Loss summaries\n",
    "            loss_sum = []\n",
    "            with tf.name_scope(\"losses\"):\n",
    "                for i in range(self.num_sources):\n",
    "                    loss_sum.append(tf.summary.scalar(\"loss_%d\" % (i+1), self.loss_n[i]))\n",
    "                loss_sum.append(tf.summary.scalar(\"loss_total\", self.loss_total))\n",
    "                self.loss_sum = tf.summary.merge(loss_sum)\n",
    "            \n",
    "            # Variable summaries\n",
    "            var_sum = []\n",
    "            with tf.name_scope(\"trainable_variables\"):\n",
    "                for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "                    with tf.name_scope(var.name[:-2]):\n",
    "                        mean = tf.reduce_mean(var)\n",
    "                        var_sum.append(tf.summary.scalar(\"mean\", mean))\n",
    "                        with tf.name_scope(\"stddev\"):\n",
    "                            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "                        var_sum.append(tf.summary.scalar(\"stddev\", stddev))\n",
    "                        var_sum.append(tf.summary.scalar(\"max\", tf.reduce_max(var)))\n",
    "                        var_sum.append(tf.summary.scalar(\"min\", tf.reduce_min(var)))\n",
    "                        var_sum.append(tf.summary.histogram(\"histogram\", var))\n",
    "                self.var_sum = tf.summary.merge(var_sum)\n",
    "    \n",
    "    def perform_training_step(self, x, y):\n",
    "        feed_dict = {self.spectrogram: x, self.targets: y}\n",
    "        loss_, _ = self.sess.run([self.loss_total, self.train_step], \n",
    "                                 feed_dict=feed_dict)\n",
    "        self.global_step += 1\n",
    "        return loss_\n",
    "    \n",
    "    def predict(self, x, y=None):\n",
    "        if y is None:\n",
    "            feed_dict = {self.spectrogram: x}\n",
    "            y_tilde_, = self.sess.run(self.y_tilde,\n",
    "                                      feed_dict=feed_dict)\n",
    "            return y_tilde_\n",
    "        else:\n",
    "            feed_dict = {self.spectrogram: x, self.targets: y}\n",
    "            y_tilde_, loss_, = self.sess.run([self.y_tilde, self.loss_total], \n",
    "                                             feed_dict=feed_dict)\n",
    "            return y_tilde_, loss_ \n",
    "    \n",
    "    def save_summaries(self, x, y):\n",
    "        feed_dict = {self.spectrogram: x, self.targets: y}\n",
    "        loss_sum_, var_sum_ = self.sess.run([self.loss_sum, self.var_sum], \n",
    "                                            feed_dict=feed_dict)\n",
    "        self.writer.add_summary(loss_sum_, global_step=self.global_step)\n",
    "        self.writer.add_summary(var_sum_, global_step=self.global_step)\n",
    "        self.writer.flush()\n",
    "    \n",
    "    def save_model(self, epoch, save_meta=True):\n",
    "        self.saver.save(self.sess, self.results_dir + \"model\", \n",
    "                        global_step=epoch, write_meta_graph=save_meta)\n",
    "    \n",
    "    def load_model(self, params_file):\n",
    "        self.saver.restore(self.sess, params_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The initial training in trial 1 on a song from the Bach10 dataset worked very well. That network only took in mag specs with 513 features, as opposed to 1025 with our current DSD100 specs. Further, trying to build graphs for the full 2049 features in the original Bach10 specs causes memory errors. Maybe it is simply too many parameters to learn for stable training. Try downsizing specs to 513 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_train_details(folder, desc):\n",
    "    f = open(folder + \"settings.txt\", \"w+\")\n",
    "    f.write(\"Description: \" + desc + \"\\n\")\n",
    "    f.write(\"Input: \" + input_dir + \"\\n\")\n",
    "    f.write(\"Output: \" + target_dir + \"\\n\")\n",
    "    f.write(\"Epochs: \" + str(num_epochs) + \"\\n\")\n",
    "    f.write(\"Learning rate: \" + str(learning_rate) + \"\\n\")\n",
    "    f.write(\"Batch size: \" + str(batch_size) + \"\\n\")\n",
    "    f.write(\"Time context: \" + str(time_context) + \"\\n\")\n",
    "    f.write(\"Dataset memory length: \" + str(mem_len) + \"\\n\")\n",
    "    f.write(\"Data format: \" + data_format + \"\\n\")\n",
    "    f.write(\"Shuffle: \" + str(shuffle) + \"\\n\")\n",
    "    f.write(\"Number of features: \" + str(ds.feat_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Reading file 1 of 5\n",
      "Reading file 2 of 5\n",
      "Reading file 3 of 5\n",
      "Reading file 4 of 5\n",
      "Reading file 5 of 5\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Creating network...\n",
      "Building input...\n",
      "Building encoder...\n",
      "Building decoder...\n",
      "Building output...\n",
      "Building losses and summaries...\n",
      "------------\n",
      "Training\n",
      "------------\n",
      "Epoch   1 of 100\n",
      "Epoch complete                        \n",
      "Elapsed time: 00:00:05\n",
      "Estimated time remaining: 00:09:18\n",
      "--------------------------------------\n",
      "Epoch   2 of 100\n",
      "Resetting database...\n",
      "Loading files 1 to 5 of 5 into memory...\n",
      "Shuffling data...\n",
      "Estimated batches remaining:  10\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6977b9100152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Perform training step and save summaries every so often\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5da37119667c>\u001b[0m in \u001b[0;36mperform_training_step\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         loss_, _ = self.sess.run([self.loss_total, self.train_step], \n\u001b[0;32m--> 216\u001b[0;31m                                  feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "desc = \"base network\"\n",
    "input_dir=\"../../data/Bach10/features_513/Mixtures/Dev/\"\n",
    "target_dir=\"../../data/Bach10/features_513/Sources/Dev/\"\n",
    "results_dir = \"../../results/trial_16/\"\n",
    "make_directory(results_dir)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "time_context = 30\n",
    "mem_len = 5e5\n",
    "data_format = \"NCHW\"\n",
    "#sources = ['bass', 'drums', 'other', 'vocal'] # DSD100\n",
    "sources = ['violin', 'clarinet', 'saxophone', 'bassoon'] # Bach10\n",
    "shuffle = True\n",
    "\n",
    "# Create dataset\n",
    "print(\"Creating dataset...\")\n",
    "ds = Dataset(input_dir=input_dir, \n",
    "              target_dir=target_dir, \n",
    "              batch_size=batch_size,\n",
    "              time_context=time_context,\n",
    "              mem_len=mem_len,\n",
    "              load_by_file=False,\n",
    "              sources=sources,\n",
    "              data_format=data_format,\n",
    "              shuffle=shuffle,\n",
    "              verbose=True)\n",
    "\n",
    "# Create network\n",
    "print(\"Creating network...\")\n",
    "net = Network(results_dir,\n",
    "              data_format=data_format,\n",
    "              time_context=time_context,\n",
    "              feat_size=ds.feat_size,\n",
    "              num_sources=ds.num_sources,\n",
    "              alpha=learning_rate,\n",
    "              train_mode=True)\n",
    "\n",
    "# Save settings\n",
    "save_train_details(results_dir, desc)\n",
    "\n",
    "print(\"------------\\nTraining\\n------------\")\n",
    "start_time = time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch %3d of %3d\" % (epoch+1, num_epochs))\n",
    "    epoch_start_time = time()\n",
    "    if epoch > 0:\n",
    "        ds.reset_database()\n",
    "    t = 0\n",
    "    while not ds.is_empty():\n",
    "        #sys.stdout.write(\"\\rEstimated batches remaining: \" + str(ds.remaining_batches()))\n",
    "        #sys.stdout.flush()\n",
    "        print(\"Estimated batches remaining: %3d\" % ds.remaining_batches(), end=\"\\r\")\n",
    "        \n",
    "        # Get batch from input data and target data\n",
    "        input_batch, target_batch = ds.create_batch()\n",
    "        \n",
    "        # Perform training step and save summaries every so often\n",
    "        loss = net.perform_training_step(input_batch, target_batch)\n",
    "        if t % 100 == 0:\n",
    "            net.save_summaries(input_batch, target_batch)\n",
    "        \n",
    "        t += 1\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    net.save_model(epoch, save_meta=(epoch==0))\n",
    "    \n",
    "    print(\"Epoch complete                        \")\n",
    "    end_time = time()\n",
    "    elap_time = end_time - start_time\n",
    "    rem_time = (end_time - epoch_start_time) * (num_epochs - epoch + 1)\n",
    "    print(\"Elapsed time: %02d:%02d:%02d\" % (elap_time // 3600, \n",
    "                                            elap_time % 3600 // 60, \n",
    "                                            elap_time % 3600 % 60))\n",
    "    print(\"Estimated time remaining: %02d:%02d:%02d\" % (rem_time // 3600, \n",
    "                                                        rem_time % 3600 // 60, \n",
    "                                                        rem_time % 3600 % 60))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing\n",
    "Yup still haven't gotten here yet :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_test_details(folder, desc):\n",
    "    f = open(folder + \"settings.txt\", \"w+\")\n",
    "    f.write(\"Description: \" + desc + \"\\n\")\n",
    "    f.write(\"Input: \" + input_dir + \"\\n\")\n",
    "    f.write(\"Output: \" + target_dir + \"\\n\")\n",
    "    f.write(\"Params: \" + params_file + \"\\n\")\n",
    "    f.write(\"Batch size: \" + str(batch_size) + \"\\n\")\n",
    "    f.write(\"Time context: \" + str(time_context) + \"\\n\")\n",
    "    f.write(\"Dataset memory length: \" + str(mem_len) + \"\\n\")\n",
    "    f.write(\"Data format: \" + data_format + \"\\n\")\n",
    "    f.write(\"Shuffle: \" + str(shuffle) + \"\\n\")\n",
    "    f.write(\"Number of features: \" + str(ds.feat_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Reading file 1 of 5\n",
      "Reading file 2 of 5\n",
      "Reading file 3 of 5\n",
      "Reading file 4 of 5\n",
      "Reading file 5 of 5\n",
      "Loading files 1 to 1 of 5 into memory...\n",
      "Creating network...\n",
      "Building input...\n",
      "Building encoder...\n",
      "Building decoder...\n",
      "Building output...\n",
      "Building losses and summaries...\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trial_16/train_data/model-99\n",
      "------------\n",
      "Testing\n",
      "------------\n",
      "File 1 loss: 0.0017; saving results...           \n",
      "Loading files 2 to 2 of 5 into memory...\n",
      "File 2 loss: 0.0017; saving results...           \n",
      "Loading files 3 to 3 of 5 into memory...\n",
      "File 3 loss: 0.0017; saving results...           \n",
      "Loading files 4 to 4 of 5 into memory...\n",
      "File 4 loss: 0.0017; saving results...           \n",
      "Loading files 5 to 5 of 5 into memory...\n",
      "File 5 loss: 0.0023; saving results...           \n"
     ]
    }
   ],
   "source": [
    "# Testing settings\n",
    "desc = \"base network\"\n",
    "input_dir=\"../../data/Bach10/features_513/Mixtures/Test/\"\n",
    "target_dir = \"../../data/Bach10/features_513/Sources/Test/\"\n",
    "results_dir = \"../../results/trial_16/test_data/\"\n",
    "make_directory(results_dir)\n",
    "params_file = \"../../results/trial_16/train_data/model-99\"\n",
    "batch_size = 32\n",
    "time_context = 30\n",
    "mem_len = 5e5\n",
    "data_format = \"NCHW\"\n",
    "#sources = ['bass', 'drums', 'other', 'vocal'] # DSD100\n",
    "sources = ['violin', 'clarinet', 'saxophone', 'bassoon'] # Bach10\n",
    "shuffle = False\n",
    "\n",
    "# Create dataset\n",
    "print(\"Creating dataset...\")\n",
    "ds = Dataset(input_dir=input_dir, \n",
    "              target_dir=target_dir, \n",
    "              batch_size=batch_size,\n",
    "              time_context=time_context,\n",
    "              mem_len=mem_len,\n",
    "              load_by_file=True,\n",
    "              sources=sources,\n",
    "              data_format=data_format,\n",
    "              shuffle=shuffle,\n",
    "              verbose=True)\n",
    "\n",
    "# Create network\n",
    "print(\"Creating network...\")\n",
    "net = Network(results_dir,\n",
    "              params_file=params_file,\n",
    "              data_format=data_format,\n",
    "              time_context=time_context,\n",
    "              feat_size=ds.feat_size,\n",
    "              num_sources=ds.num_sources,\n",
    "              train_mode=False)\n",
    "\n",
    "# Save settings\n",
    "save_test_details(results_dir, desc)\n",
    "\n",
    "print(\"------------\\nTesting\\n------------\")\n",
    "t = 0 # batch iteration\n",
    "pred = []\n",
    "loss = 0\n",
    "while not ds.is_empty():\n",
    "    start_time = time()\n",
    "    #sys.stdout.write(\"\\rEstimated batches remaining: \" + str(ds.remaining_batches()))\n",
    "    #sys.stdout.flush()\n",
    "    print(\"Estimated files remaining: %3d\" % ds.remaining_files(), end=\"\\r\")\n",
    "\n",
    "    # Get batch from input data and target data\n",
    "    input_batch, target_batch = ds.create_batch()\n",
    "    \n",
    "    # Make prediction\n",
    "    pred_, loss_ = net.predict(input_batch, target_batch)\n",
    "    \n",
    "    # Store prediction and loss\n",
    "    pred.append(np.reshape(pred_, [-1, ds.feat_size, ds.num_sources]))\n",
    "    loss += loss_\n",
    "\n",
    "    # Save prediction if reached end of current file\n",
    "    if ds.load_next or ds.reset:\n",
    "        print(\"File %d loss: %.4f; saving results...           \" % (t+1, loss))\n",
    "       \n",
    "        # Get last window\n",
    "        if data_format == \"NCHW\":\n",
    "            input_shape = [1, 1, time_context, -1]\n",
    "            target_shape = [1, ds.num_sources, time_context, -1]\n",
    "        elif data_format == \"NHWC\":\n",
    "            input_shape = [1, time_context, 1, -1]\n",
    "            target_shape = [1, time_context, ds.num_sources, -1]\n",
    "        last_input = np.reshape(ds.inputs_[-time_context:], input_shape)\n",
    "        last_target = np.reshape(ds.sources_[-time_context:], target_shape)\n",
    "        pred_, _ = net.predict(last_input, last_target)\n",
    "        pred_ = np.reshape(pred_, [-1, ds.feat_size, ds.num_sources])\n",
    "    \n",
    "        # Add last window to predictions, averaging overlapping time points\n",
    "        pred = np.concatenate(pred, axis=0)\n",
    "        overlap = ds.shapes[t, 0] - pred.shape[0]\n",
    "        if overlap == 0: overlap = None\n",
    "        pred[-time_context:-overlap] = \\\n",
    "            (pred[-time_context:-overlap] + pred_[:-overlap]) / 2.0\n",
    "        pred = np.concatenate([pred, pred_[-overlap:]], axis=0)\n",
    "       \n",
    "        # Save source predictions\n",
    "        for i, s in enumerate(sources):\n",
    "            np.save(results_dir + \"%02d-pred-%s\" % (t+1, s), pred[:, :, i])\n",
    "        \n",
    "        # Increment counters\n",
    "        loss = 0\n",
    "        pred = []\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-DieSonn-mix.mag.npy (2870, 513)\n",
      "01-pred-bassoon.npy (2870, 513)\n",
      "07-HerrGot-mix.mag.npy (2808, 513)\n",
      "02-pred-bassoon.npy (2808, 513)\n",
      "08-FuerDeinenThro-mix.mag.npy (2865, 513)\n",
      "03-pred-bassoon.npy (2865, 513)\n",
      "09-Jesu-mix.mag.npy (2531, 513)\n",
      "04-pred-bassoon.npy (2531, 513)\n",
      "10-NunBitte-mix.mag.npy (3223, 513)\n",
      "05-pred-bassoon.npy (3223, 513)\n"
     ]
    }
   ],
   "source": [
    "for f, f_ in zip(sorted(os.listdir(input_dir)), sorted(os.listdir(results_dir))[::4]):\n",
    "    print(f, np.load(d+f).shape)\n",
    "    print(f_, np.load(d_+f_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Old code\n",
    "Just stashing away old code in case I need to reference or pull from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal']):\n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir)])\n",
    "        target_files = sorted([os.path.join(target_dir, f) for f in os.listdir(target_dir)])\n",
    "        self.source_files = []\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "\n",
    "        # Get shapes of data files\n",
    "        input_shapes = []\n",
    "        for f in self.input_files:\n",
    "            input_shapes.append(np.load(f, mmap_mode='r').shape)\n",
    "        input_shapes = np.asarray(input_shapes)\n",
    "        self.t_total = np.sum(input_shapes[:, 0])\n",
    "        self.feat_size = input_shapes[0, 1]\n",
    "        if not (input_shapes[:, 1] == self.feat_size).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        \n",
    "        # Create memmap array of all files\n",
    "        # From https://stackoverflow.com/questions/13780907/is-it-possible-to-np-concatenate-memory-mapped-files\n",
    "        # Initialize memmap objects\n",
    "        self.inputs = np.memmap(self.input_files[0], \n",
    "                                dtype='float64',\n",
    "                                mode='r+',\n",
    "                                shape=(self.t_total, self.feat_size),\n",
    "                                order='C')\n",
    "        self.sources = []\n",
    "        for i in range(len(sources)):\n",
    "            self.sources.append(np.memmap(self.source_files[i][0], \n",
    "                                          dtype='float64',\n",
    "                                          mode='r+',\n",
    "                                          shape=(self.t_total, self.feat_size),\n",
    "                                          order='C'))\n",
    "        \n",
    "        # Read values from subsequent files into initialized memmap\n",
    "        idx = input_shapes[0, 0]\n",
    "        for i in range(1, len(self.input_files)):\n",
    "            print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            # Load mem map of mixture file\n",
    "            #f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            f_in = np.memmap(self.input_files[i],\n",
    "                            dtype='float64',\n",
    "                                mode='r',\n",
    "                                shape=(input_shapes[i,0], self.feat_size),\n",
    "                                order='C')\n",
    "            self.inputs[idx:idx+f_in.shape[0]] = f_in\n",
    "            \n",
    "            # Load mem maps of source files\n",
    "            for j in range(len(sources)):\n",
    "                #f_s = np.load(self.source_files[j][i], mmap_mode='r')\n",
    "                f_s = np.memmap(self.source_files[j][i],\n",
    "                                dtype='float64',\n",
    "                                mode='r',\n",
    "                                shape=(input_shapes[i,0], self.feat_size),\n",
    "                                order='C')\n",
    "                self.sources[j][idx:idx+f_s.shape[0]] = f_s\n",
    "            \n",
    "            # Increment index\n",
    "            idx += f_in.shape[0]\n",
    "        \n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        idx_start = self.t\n",
    "        self.inputs_ = self.inputs[self.t:min(self.t+self.mem_len, self.t_total)]\n",
    "        self.sources_ = [s[self.t:min(self.t+self.mem_len, self.t_total)] \n",
    "                         for s in self.sources]\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def reset_database(self):\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Reset database if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        \n",
    "        # Load more data into memory if needed\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        self.reset = False\n",
    "        if self.t + batch_len > self.t_total:\n",
    "            batch_len = self.t_total - self.t\n",
    "            self.reset = True\n",
    "        elif self.t_ + batch_len > self.inputs_.shape[0]:\n",
    "            self.load_memory()\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[self.t_:self.t_+batch_len],\n",
    "                                  [self.batch_size, self.time_context, self.feat_size])\n",
    "        sources_batch = [np.reshape(s[self.t_:self.t_+batch_len],\n",
    "                                    [self.batch_size, self.time_context, self.feat_size])\n",
    "                         for s in self.sources_]\n",
    "        self.t_ += batch_len\n",
    "        self.t  += batch_len\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal'],\n",
    "                 data_format=\"NHWC\",\n",
    "                 shuffle_len=30,\n",
    "                 verbose=True):\n",
    "        # Grab arguments\n",
    "        self.batch_size = batch_size\n",
    "        self.time_context = time_context\n",
    "        self.num_sources = len(sources)\n",
    "        self.data_format = data_format\n",
    "        self.shuffle_len = shuffle_len\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) \n",
    "                                   for f in os.listdir(input_dir) if \"mag\" in f])\n",
    "        target_files = sorted([os.path.join(target_dir, f) \n",
    "                               for f in os.listdir(target_dir) if \"mag\" in f])\n",
    "        self.source_files = [] # [source_id][t]\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "        \n",
    "        # Read mem maps of data files\n",
    "        self.inputs = []\n",
    "        self.sources = [] # [t][source_id]\n",
    "        self.shapes = []\n",
    "        shapes_ = [] # placeholder to ensure all associated shapes equal\n",
    "        for i in range(len(self.input_files)):\n",
    "            if verbose:\n",
    "                print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            \n",
    "            # Add mem map of mixture file\n",
    "            f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            self.inputs.append(f_in)\n",
    "            \n",
    "            # Add mem maps of source files\n",
    "            f_s = [np.load(self.source_files[j][i], mmap_mode='r') \n",
    "                   for j in range(len(sources))]\n",
    "            self.sources.append(f_s)\n",
    "            \n",
    "            # Get shapes\n",
    "            self.shapes.append(f_in.shape)\n",
    "            shapes_.append([f.shape for f in f_s])\n",
    "        \n",
    "        # Set class variables\n",
    "        self.shapes = np.asarray(self.shapes)\n",
    "        self.t_total = np.sum(self.shapes[:, 0])\n",
    "        self.feat_size = self.shapes[0, 1]\n",
    "        \n",
    "        # Check that shapes [index, ch, shape] are equal for each time point\n",
    "        shapes_ = np.concatenate([self.shapes[:, np.newaxis, :], np.asarray(shapes_)], axis=1)\n",
    "        if not (shapes_[:, :, 0].T == shapes_[:, 0, 0]).all():\n",
    "            raise ValueError(\"All spectrograms must be of same length.\")\n",
    "        if not (shapes_[:, :, 1].T == shapes_[:, 0, 1]).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        shapes_ = None # release from memory\n",
    "            \n",
    "        # Set variables to track time position\n",
    "        self.t_c = np.cumsum(self.shapes[:, 0])\n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_next = False # if True, load next batch of files\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        # Get indices of files corresponding to next mem_len time points\n",
    "        t_start = self.t\n",
    "        t_end = self.t + self.mem_len\n",
    "        idx_start = np.searchsorted(self.t_c, t_start, side='right')\n",
    "        idx_end = np.searchsorted(self.t_c, t_end, side='right')\n",
    "        if self.verbose:\n",
    "            #print(\"Indices t %d to %d\" % (t_start, t_end))\n",
    "            print(\"Loading files %d to %d of %d into memory...\" % (idx_start+1, idx_end, len(self.inputs)))\n",
    "        \n",
    "        # Load from mem maps of files into shape [time, features, [num_sources]]\n",
    "        f_in = [self.inputs[t] for t in range(idx_start, idx_end)] # get list of next files\n",
    "        self.inputs_ = None # clear previous memory (avoids temporary double storage)\n",
    "        self.inputs_ = np.concatenate(f_in, axis=0) # loads into memory\n",
    "        f_s = [np.asarray(self.sources[t]) for t in range(idx_start, idx_end)]\n",
    "        self.sources_ = None\n",
    "        self.sources_ = np.transpose(np.concatenate(f_s, axis=1), axes=[1, 2, 0]) # loads into memory\n",
    "                                          \n",
    "        # Reset counter\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def reset_database(self):\n",
    "        if self.verbose:\n",
    "            print(\"Resetting database...\")\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Load memory if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        elif self.load_next:\n",
    "            self.load_memory()\n",
    "        \n",
    "        # Determine batch length and set loading bools for next batch\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        rem = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        if self.t + batch_len > self.t_total: # reach end of all data\n",
    "            batch_len = (self.t_total - self.t) // self.time_context * self.time_context\n",
    "            rem = (self.t_total - self.t) % self.time_context\n",
    "            self.reset = True\n",
    "        elif self.t_ + batch_len > self.inputs_.shape[0]: # reach end of loaded data\n",
    "            batch_len = (self.inputs_.shape[0] - self.t_) // self.time_context * self.time_context\n",
    "            rem = (self.inputs_.shape[0] - self.t_) % self.time_context\n",
    "            self.load_next = True\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[self.t_:self.t_+batch_len],\n",
    "                                  [-1, self.time_context, self.feat_size, 1])\n",
    "        sources_batch = np.reshape(self.sources_[self.t_:self.t_+batch_len],\n",
    "                                    [-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        if self.data_format == \"NCHW\":\n",
    "            inputs_batch = np.transpose(inputs_batch, axes=[0, 3, 1, 2])\n",
    "            sources_batch = np.transpose(sources_batch, axes=[0, 3, 1, 2])\n",
    "        \n",
    "        # Increment counters\n",
    "        self.t_ += batch_len + rem \n",
    "        self.t  += batch_len + rem\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return ds.reset\n",
    "    \n",
    "    def remaining_batches(self):\n",
    "        return math.ceil((self.inputs_.shape[0] - self.t_) \n",
    "                         / (self.batch_size * self.time_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_dir, \n",
    "                 target_dir, \n",
    "                 batch_size=32,\n",
    "                 time_context=30,\n",
    "                 mem_len=1e5,\n",
    "                 sources=['bass', 'drums', 'other', 'vocal'],\n",
    "                 data_format=\"NHWC\",\n",
    "                 shuffle_len=30,\n",
    "                 verbose=True):\n",
    "        # Grab arguments\n",
    "        self.batch_size = batch_size\n",
    "        self.time_context = time_context\n",
    "        self.num_sources = len(sources)\n",
    "        self.data_format = data_format\n",
    "        self.shuffle_len = shuffle_len\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Get data files\n",
    "        self.input_files = sorted([os.path.join(input_dir, f) \n",
    "                                   for f in os.listdir(input_dir) if \"mag\" in f])\n",
    "        target_files = sorted([os.path.join(target_dir, f) \n",
    "                               for f in os.listdir(target_dir) if \"mag\" in f])\n",
    "        self.source_files = [] # [source_id][t]\n",
    "        for i, s in enumerate(sources):\n",
    "            self.source_files.append([t for t in target_files if s in t])\n",
    "        \n",
    "        # Read mem maps of data files\n",
    "        self.inputs = []\n",
    "        self.sources = [] # [t][source_id]\n",
    "        self.shapes = []\n",
    "        shapes_ = [] # placeholder to ensure all associated shapes equal\n",
    "        for i in range(len(self.input_files)):\n",
    "            if verbose:\n",
    "                print(\"Reading file %d of %d\" % (i+1, len(self.input_files)))\n",
    "            \n",
    "            # Add mem map of mixture file\n",
    "            f_in = np.load(self.input_files[i], mmap_mode='r')\n",
    "            self.inputs.append(f_in)\n",
    "            \n",
    "            # Add mem maps of source files\n",
    "            f_s = [np.load(self.source_files[j][i], mmap_mode='r') \n",
    "                   for j in range(len(sources))]\n",
    "            self.sources.append(f_s)\n",
    "            \n",
    "            # Get shapes\n",
    "            self.shapes.append(f_in.shape)\n",
    "            shapes_.append([f.shape for f in f_s])\n",
    "        \n",
    "        # Set class variables\n",
    "        self.shapes = np.asarray(self.shapes)\n",
    "        self.t_total = np.sum(self.shapes[:, 0])\n",
    "        self.feat_size = self.shapes[0, 1]\n",
    "        \n",
    "        # Check that shapes [index, ch, shape] are equal for each time point\n",
    "        shapes_ = np.concatenate([self.shapes[:, np.newaxis, :], np.asarray(shapes_)], axis=1)\n",
    "        if not (shapes_[:, :, 0].T == shapes_[:, 0, 0]).all():\n",
    "            raise ValueError(\"All spectrograms must be of same length.\")\n",
    "        if not (shapes_[:, :, 1].T == shapes_[:, 0, 1]).all():\n",
    "            raise ValueError(\"All spectograms must have same number of features.\")\n",
    "        shapes_ = None # release from memory\n",
    "            \n",
    "        # Set variables to track time position\n",
    "        self.t_c = np.cumsum(self.shapes[:, 0])\n",
    "        self.mem_len = mem_len\n",
    "        self.t = 0 # current global time index\n",
    "        self.t_ = 0 # current memory time index\n",
    "        self.reset = False # if True, reset database\n",
    "        self.load_next = False # if True, load next batch of files\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self):\n",
    "        \"\"\"Loads part of dataset into memory.\"\"\"\n",
    "        # Get indices of files corresponding to next mem_len time points\n",
    "        t_start = self.t\n",
    "        t_end = self.t + self.mem_len\n",
    "        idx_start = np.searchsorted(self.t_c, t_start, side='right')\n",
    "        idx_end = np.searchsorted(self.t_c, t_end, side='right')\n",
    "        if self.verbose:\n",
    "            print(\"Loading files %d to %d of %d into memory...\" % (idx_start+1, idx_end, len(self.inputs)))\n",
    "        \n",
    "        # Load from mem maps of files into shape [time, features, [num_sources]]\n",
    "        f_in = [self.inputs[t] for t in range(idx_start, idx_end)] # get list of next files\n",
    "        self.inputs_ = None # clear previous memory (avoids temporary double storage)\n",
    "        self.inputs_ = np.concatenate(f_in, axis=0) # loads into memory\n",
    "        f_s = [np.asarray(self.sources[t]) for t in range(idx_start, idx_end)]\n",
    "        self.sources_ = None\n",
    "        self.sources_ = np.transpose(np.concatenate(f_s, axis=1), axes=[1, 2, 0]) # loads into memory\n",
    "                                          \n",
    "        # Set vector of random start points from loaded memory\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        self.t_rand = np.asarray([batch_len * n \n",
    "                                  for n in range(self.inputs_.shape[0] // batch_len + 1)])\n",
    "        np.random.shuffle(self.t_rand)\n",
    "        self.t_idx = 0\n",
    "        self.t_ = 0\n",
    "    \n",
    "    def reset_database(self):\n",
    "        if self.verbose:\n",
    "            print(\"Resetting database...\")\n",
    "        self.t = 0\n",
    "        self.t_ = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        self.load_memory()\n",
    "    \n",
    "    def create_batch(self):\n",
    "        \"\"\"Creates batch of training data from datset\"\"\"\n",
    "        # Load memory if exhausted\n",
    "        if self.reset:\n",
    "            self.reset_database()\n",
    "        elif self.load_next:\n",
    "            self.load_memory()\n",
    "\n",
    "        # Determine batch length and set loading bools for next batch\n",
    "        batch_len = self.batch_size * self.time_context\n",
    "        rem = 0\n",
    "        self.reset = False\n",
    "        self.load_next = False\n",
    "        t_i = self.t_rand[self.t_idx]\n",
    "        if self.t + batch_len >= self.t_total: # reach end of all data\n",
    "            #batch_len = (self.t_total - self.t) // self.time_context * self.time_context\n",
    "            #rem = (self.t_total - self.t) % self.time_context\n",
    "            self.reset = True\n",
    "        if t_i + batch_len >= self.inputs_.shape[0]: # reach end of loaded data\n",
    "            batch_len = (self.inputs_.shape[0] - t_i) // self.time_context * self.time_context\n",
    "            rem = (self.inputs_.shape[0] - t_i) % self.time_context\n",
    "        if self.t_idx >= len(self.t_rand) - 1: # exhausted all loaded data\n",
    "            self.load_next = True\n",
    "        \n",
    "        # Get batches of inputs and sources\n",
    "        inputs_batch = np.reshape(self.inputs_[t_i:t_i+batch_len],\n",
    "                                  [-1, self.time_context, self.feat_size, 1])\n",
    "        sources_batch = np.reshape(self.sources_[t_i:t_i+batch_len],\n",
    "                                    [-1, self.time_context, self.feat_size, self.num_sources])\n",
    "        if self.data_format == \"NCHW\":\n",
    "            inputs_batch = np.transpose(inputs_batch, axes=[0, 3, 1, 2])\n",
    "            sources_batch = np.transpose(sources_batch, axes=[0, 3, 1, 2])\n",
    "        \n",
    "        # Increment counters\n",
    "        self.t  += batch_len + rem\n",
    "        self.t_ += batch_len + rem\n",
    "        self.t_idx += 1\n",
    "        \n",
    "        return inputs_batch, sources_batch\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return ds.reset\n",
    "    \n",
    "    def remaining_batches(self):\n",
    "        return math.ceil((self.inputs_.shape[0] - self.t_) \n",
    "                         / (self.batch_size * self.time_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old batch handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batches(data, batch_size):\n",
    "    \"\"\"Reshapes data into batches of input size for network\"\"\"\n",
    "    batches = []\n",
    "    time_batches = data.shape[1] // time_context\n",
    "    freq_batches = data.shape[2] // feat_size\n",
    "    for t in range(time_batches):\n",
    "        for f in range(freq_batches):\n",
    "            batches.append(data[:, t*time_context:(t+1)*time_context, f*feat_size:(f+1)*feat_size])\n",
    "    return np.asarray(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "params_dir = results_dir + \"params/\"\n",
    "make_directory(params_dir)\n",
    "input_file = \"./features/02-AchLiebenChristen__m_.data\"\n",
    "shape_file = \"./features/02-AchLiebenChristen__m_.shape\"\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "f_in = np.fromfile(input_file)\n",
    "if shape_file is not None:\n",
    "    f_shape = get_shape(shape_file)\n",
    "    f_in = np.reshape(f_in, f_shape)\n",
    "input_data = create_batches(f_in[0:1], batch_size) # mixed input\n",
    "target_data = create_batches(f_in[1:], batch_size) # separate sources\n",
    "iter_size = len(input_data) // batch_size\n",
    "\n",
    "# Initialize graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(iter_size):\n",
    "        # Get batch from input data and target data\n",
    "        input_batch = input_data[i*batch_size:(i+1)*batch_size] # magnitude spectrogram of whole\n",
    "        target_batch = target_data[i*batch_size:(i+1)*batch_size] # magnitude spectrogram of sources\n",
    "        \n",
    "        # Perform training step\n",
    "        feed_dict = {spectrogram: input_batch, targets: target_batch}\n",
    "        loss_sum_, _ = sess.run([loss_sum, train_step], \n",
    "                                feed_dict=feed_dict)\n",
    "        writer.add_summary(loss_sum_, global_step=global_step)\n",
    "        writer.flush()\n",
    "        global_step += 1\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    saver.save(sess, params_dir + \"model\", \n",
    "               global_step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset testing (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file 1 of 5\n",
      "Reading file 2 of 5\n",
      "Reading file 3 of 5\n",
      "Reading file 4 of 5\n",
      "Reading file 5 of 5\n",
      "Indices t 0 to 100000\n",
      "Loading files 1 to 2 of 5 into memory...\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(input_dir='../../data/DSD100/features_mini/Mixtures/Dev/', \n",
    "             target_dir='../../data/DSD100/features_mini/Sources/Dev/', \n",
    "             batch_size=32,\n",
    "             time_context=30,\n",
    "             sources=['bass', 'drums', 'other', 'vocal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1, t 0, t_ 0\n",
      "Batch 2, t 960, t_ 960\n",
      "Batch 3, t 1920, t_ 1920\n",
      "Batch 4, t 2880, t_ 2880\n",
      "Batch 5, t 3840, t_ 3840\n",
      "Batch 6, t 4800, t_ 4800\n",
      "Batch 7, t 5760, t_ 5760\n",
      "Batch 8, t 6720, t_ 6720\n",
      "Batch 9, t 7680, t_ 7680\n",
      "Batch 10, t 8640, t_ 8640\n",
      "Batch 11, t 9600, t_ 9600\n",
      "Batch 12, t 10560, t_ 10560\n",
      "Batch 13, t 11520, t_ 11520\n",
      "Batch 14, t 12480, t_ 12480\n",
      "Batch 15, t 13440, t_ 13440\n",
      "Batch 16, t 14400, t_ 14400\n",
      "Batch 17, t 15360, t_ 15360\n",
      "Batch 18, t 16320, t_ 16320\n",
      "Batch 19, t 17280, t_ 17280\n",
      "Batch 20, t 18240, t_ 18240\n",
      "Batch 21, t 19200, t_ 19200\n",
      "Batch 22, t 20160, t_ 20160\n",
      "Batch 23, t 21120, t_ 21120\n",
      "Batch 24, t 22080, t_ 22080\n",
      "Batch 25, t 23040, t_ 23040\n",
      "Batch 26, t 24000, t_ 24000\n",
      "Batch 27, t 24960, t_ 24960\n",
      "Batch 28, t 25920, t_ 25920\n",
      "Batch 29, t 26880, t_ 26880\n",
      "Batch 30, t 27840, t_ 27840\n",
      "Batch 31, t 28800, t_ 28800\n",
      "Batch 32, t 29760, t_ 29760\n",
      "Batch 33, t 30720, t_ 30720\n",
      "Batch 34, t 31680, t_ 31680\n",
      "Batch 35, t 32640, t_ 32640\n",
      "Batch 36, t 33600, t_ 33600\n",
      "Batch 37, t 34560, t_ 34560\n",
      "Batch 38, t 35520, t_ 35520\n",
      "Batch 39, t 36480, t_ 36480\n",
      "Batch 40, t 37440, t_ 37440\n",
      "Batch 41, t 38400, t_ 38400\n",
      "Batch 42, t 39360, t_ 39360\n",
      "Batch 43, t 40320, t_ 40320\n",
      "Batch 44, t 41280, t_ 41280\n",
      "Batch 45, t 42240, t_ 42240\n",
      "Batch 46, t 43200, t_ 43200\n",
      "Batch 47, t 44160, t_ 44160\n",
      "Batch 48, t 45120, t_ 45120\n",
      "Batch 49, t 46080, t_ 46080\n",
      "Batch 50, t 47040, t_ 47040\n",
      "Batch 51, t 48000, t_ 48000\n",
      "Batch 52, t 48960, t_ 48960\n",
      "Batch 53, t 49920, t_ 49920\n",
      "Batch 54, t 50880, t_ 50880\n",
      "Batch 55, t 51840, t_ 51840\n",
      "Batch 56, t 52800, t_ 52800\n",
      "Batch 57, t 53760, t_ 53760\n",
      "Batch 58, t 54720, t_ 54720\n",
      "Batch 59, t 55680, t_ 55680\n",
      "Batch 60, t 56640, t_ 56640\n",
      "Batch 61, t 57600, t_ 57600\n",
      "Batch 62, t 58560, t_ 58560\n",
      "Batch 63, t 59520, t_ 59520\n",
      "Batch 64, t 60480, t_ 60480\n",
      "Batch 65, t 61440, t_ 61440\n",
      "Batch 66, t 62400, t_ 62400\n",
      "Batch 67, t 63360, t_ 63360\n",
      "Batch 68, t 64320, t_ 64320\n",
      "Batch 69, t 65280, t_ 65280\n",
      "Batch 70, t 66240, t_ 66240\n",
      "Batch 71, t 67200, t_ 67200\n",
      "Batch 72, t 68160, t_ 68160\n",
      "Batch 73, t 69120, t_ 69120\n",
      "Batch 74, t 70080, t_ 70080\n",
      "Batch 75, t 71040, t_ 71040\n",
      "Batch 76, t 71626, t_ 71626\n",
      "Indices t 71626 to 171626\n",
      "Loading files 3 to 5 of 5 into memory...\n",
      "Batch 77, t 72586, t_ 960\n",
      "Batch 78, t 73546, t_ 1920\n",
      "Batch 79, t 74506, t_ 2880\n",
      "Batch 80, t 75466, t_ 3840\n",
      "Batch 81, t 76426, t_ 4800\n",
      "Batch 82, t 77386, t_ 5760\n",
      "Batch 83, t 78346, t_ 6720\n",
      "Batch 84, t 79306, t_ 7680\n",
      "Batch 85, t 80266, t_ 8640\n",
      "Batch 86, t 81226, t_ 9600\n",
      "Batch 87, t 82186, t_ 10560\n",
      "Batch 88, t 83146, t_ 11520\n",
      "Batch 89, t 84106, t_ 12480\n",
      "Batch 90, t 85066, t_ 13440\n",
      "Batch 91, t 86026, t_ 14400\n",
      "Batch 92, t 86986, t_ 15360\n",
      "Batch 93, t 87946, t_ 16320\n",
      "Batch 94, t 88906, t_ 17280\n",
      "Batch 95, t 89866, t_ 18240\n",
      "Batch 96, t 90826, t_ 19200\n",
      "Batch 97, t 91786, t_ 20160\n",
      "Batch 98, t 92746, t_ 21120\n",
      "Batch 99, t 93706, t_ 22080\n",
      "Batch 100, t 94666, t_ 23040\n",
      "Batch 101, t 95626, t_ 24000\n",
      "Batch 102, t 96586, t_ 24960\n",
      "Batch 103, t 97546, t_ 25920\n",
      "Batch 104, t 98506, t_ 26880\n",
      "Batch 105, t 99466, t_ 27840\n",
      "Batch 106, t 100426, t_ 28800\n",
      "Batch 107, t 101386, t_ 29760\n",
      "Batch 108, t 102346, t_ 30720\n",
      "Batch 109, t 103306, t_ 31680\n",
      "Batch 110, t 104266, t_ 32640\n",
      "Batch 111, t 105226, t_ 33600\n",
      "Batch 112, t 106186, t_ 34560\n",
      "Batch 113, t 107146, t_ 35520\n",
      "Batch 114, t 108106, t_ 36480\n",
      "Batch 115, t 109066, t_ 37440\n",
      "Batch 116, t 110026, t_ 38400\n",
      "Batch 117, t 110986, t_ 39360\n",
      "Batch 118, t 111946, t_ 40320\n",
      "Batch 119, t 112906, t_ 41280\n",
      "Batch 120, t 113866, t_ 42240\n",
      "Batch 121, t 114826, t_ 43200\n",
      "Batch 122, t 115786, t_ 44160\n",
      "Batch 123, t 116746, t_ 45120\n",
      "Batch 124, t 117706, t_ 46080\n",
      "Batch 125, t 118666, t_ 47040\n",
      "Batch 126, t 119626, t_ 48000\n",
      "Batch 127, t 120586, t_ 48960\n",
      "Batch 128, t 121546, t_ 49920\n",
      "Batch 129, t 122506, t_ 50880\n",
      "Batch 130, t 123466, t_ 51840\n",
      "Batch 131, t 124426, t_ 52800\n",
      "Batch 132, t 125386, t_ 53760\n",
      "Batch 133, t 126346, t_ 54720\n",
      "Batch 134, t 127306, t_ 55680\n",
      "Batch 135, t 128266, t_ 56640\n",
      "Batch 136, t 129226, t_ 57600\n",
      "Batch 137, t 130186, t_ 58560\n",
      "Batch 138, t 131146, t_ 59520\n",
      "Batch 139, t 132106, t_ 60480\n",
      "Batch 140, t 133066, t_ 61440\n",
      "Batch 141, t 134026, t_ 62400\n",
      "Batch 142, t 134986, t_ 63360\n",
      "Batch 143, t 135946, t_ 64320\n",
      "Batch 144, t 136906, t_ 65280\n",
      "Batch 145, t 137866, t_ 66240\n",
      "Batch 146, t 138826, t_ 67200\n",
      "Batch 147, t 139786, t_ 68160\n",
      "Batch 148, t 140746, t_ 69120\n",
      "Batch 149, t 141706, t_ 70080\n",
      "Batch 150, t 142666, t_ 71040\n",
      "Batch 151, t 143626, t_ 72000\n",
      "Batch 152, t 144586, t_ 72960\n",
      "Batch 153, t 145546, t_ 73920\n",
      "Batch 154, t 146506, t_ 74880\n",
      "Batch 155, t 147466, t_ 75840\n",
      "Batch 156, t 148426, t_ 76800\n",
      "Batch 157, t 149386, t_ 77760\n",
      "Batch 158, t 150346, t_ 78720\n",
      "Batch 159, t 151306, t_ 79680\n",
      "Batch 160, t 152266, t_ 80640\n",
      "Batch 161, t 153226, t_ 81600\n",
      "Batch 162, t 154186, t_ 82560\n",
      "Batch 163, t 155146, t_ 83520\n",
      "Batch 164, t 156106, t_ 84480\n",
      "Batch 165, t 157066, t_ 85440\n",
      "Batch 166, t 158026, t_ 86400\n",
      "Batch 167, t 158986, t_ 87360\n",
      "Batch 168, t 159946, t_ 88320\n",
      "Batch 169, t 160906, t_ 89280\n",
      "Batch 170, t 161866, t_ 90240\n",
      "Batch 171, t 162826, t_ 91200\n",
      "Batch 172, t 163786, t_ 92160\n",
      "Batch 173, t 164746, t_ 93120\n",
      "Batch 174, t 165706, t_ 94080\n",
      "Batch 175, t 166666, t_ 95040\n",
      "Batch 176, t 166932, t_ 95306\n",
      "Reseting database...\n",
      "Indices t 0 to 100000\n",
      "Loading files 1 to 2 of 5 into memory...\n",
      "Batch 177, t 960, t_ 960\n",
      "Batch 178, t 1920, t_ 1920\n",
      "Batch 179, t 2880, t_ 2880\n",
      "Batch 180, t 3840, t_ 3840\n",
      "Batch 181, t 4800, t_ 4800\n",
      "Batch 182, t 5760, t_ 5760\n",
      "Batch 183, t 6720, t_ 6720\n",
      "Batch 184, t 7680, t_ 7680\n",
      "Batch 185, t 8640, t_ 8640\n",
      "Batch 186, t 9600, t_ 9600\n",
      "Batch 187, t 10560, t_ 10560\n",
      "Batch 188, t 11520, t_ 11520\n",
      "Batch 189, t 12480, t_ 12480\n",
      "Batch 190, t 13440, t_ 13440\n",
      "Batch 191, t 14400, t_ 14400\n",
      "Batch 192, t 15360, t_ 15360\n",
      "Batch 193, t 16320, t_ 16320\n",
      "Batch 194, t 17280, t_ 17280\n",
      "Batch 195, t 18240, t_ 18240\n",
      "Batch 196, t 19200, t_ 19200\n",
      "Batch 197, t 20160, t_ 20160\n",
      "Batch 198, t 21120, t_ 21120\n",
      "Batch 199, t 22080, t_ 22080\n",
      "Batch 200, t 23040, t_ 23040\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(\"Batch %d, t %d, t_ %d\" % (i+1, ds.t, ds.t_))\n",
    "    _, _ = ds.create_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph building without class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Setttings\n",
    "#data_format = \"NHWC\" # if using cpu\n",
    "data_format = \"NCHW\" # if using gpu\n",
    "results_dir = \"./results/trial_1/\"\n",
    "make_directory(results_dir)\n",
    "time_context = 30\n",
    "feat_size = 513\n",
    "num_sources = 4\n",
    "eps = 1e-18 # numerical stability\n",
    "alpha = 0.001 # learning rate\n",
    "\n",
    "# Data formatting\n",
    "if data_format == \"NHWC\":\n",
    "    input_shape = [None, time_context, feat_size, 1]\n",
    "    target_shape = [None, time_context, feat_size, num_sources]\n",
    "    channel_dim = 3\n",
    "elif data_format == \"NCHW\":\n",
    "    input_shape = [None, 1, time_context, feat_size]\n",
    "    target_shape = [None, num_sources, time_context, feat_size]\n",
    "    channel_dim = 1\n",
    "else:\n",
    "    raise ValueError(\"Unknown data format \\\"\" + data_format + \"\\\"\")\n",
    "spectrogram = tf.placeholder(tf.float32, \n",
    "                             shape=input_shape, \n",
    "                             name=\"magnitude_spectrogram\")\n",
    "\n",
    "# Convolutional layer 1\n",
    "conv1 = conv2d(spectrogram,\n",
    "               num_outputs=30,\n",
    "               kernel_size=[1, 30],\n",
    "               stride=[1, 4],\n",
    "               padding=\"VALID\",\n",
    "               data_format=data_format,\n",
    "               weights_initializer=\"xavier\",\n",
    "               biases_initializer=[\"constant\", 0.0],\n",
    "               scope=\"CONV_1\")\n",
    "\n",
    "# Convolutional layer 2\n",
    "conv2 = conv2d(conv1,\n",
    "               num_outputs=30,\n",
    "               kernel_size=[int(2*time_context/3), 1],\n",
    "               stride=[1, 1],\n",
    "               padding=\"VALID\",\n",
    "               data_format=data_format,\n",
    "               weights_initializer=\"xavier\",\n",
    "               biases_initializer=[\"constant\", 0.0],\n",
    "               scope=\"CONV_2\")\n",
    "conv2_flat = flatten(conv2,\n",
    "                     data_format=data_format,\n",
    "                     scope=\"CONV_2_FLAT\")\n",
    "\n",
    "# Fully-connected layer 1 (encoding)\n",
    "fc1 = fully_connected(conv2_flat,\n",
    "                      num_outputs=256,\n",
    "                      activation_fn=\"relu\",\n",
    "                      weights_initializer=\"xavier\",\n",
    "                      biases_initializer=[\"constant\", 0.0],\n",
    "                      scope=\"FC_1\")\n",
    "\n",
    "# Get shapes for building decoding layers\n",
    "batch_size = tf.shape(spectrogram)[0]\n",
    "conv1_shape = conv1.get_shape().as_list()\n",
    "conv2_shape = conv2.get_shape().as_list()\n",
    "conv2_size = conv2_shape[1] * conv2_shape[2] * conv2_shape[3]\n",
    "\n",
    "# Build decoder for each source\n",
    "fc2, convt1, convt2 = [], [], []\n",
    "for i in range(num_sources):\n",
    "    # Fully-connected layer 2 (decoding)\n",
    "    fc2_i = fully_connected(fc1,\n",
    "                            num_outputs=conv2_size,\n",
    "                            activation_fn=\"relu\",\n",
    "                            weights_initializer=\"xavier\",\n",
    "                            biases_initializer=[\"constant\", 0.0],\n",
    "                            scope=\"FC_2_%d\" % (i+1))\n",
    "    fc2.append(fc2_i)\n",
    "    \n",
    "    # Convolutional transpose layer 1\n",
    "    # Side note: tf.reshape() can infer size of one dimension given rest, so -1 okay\n",
    "    #            tf.nn.conv2d_transpose() must know exact dimensions, but batch size can\n",
    "    #                be inferred at runtime using tf.shape()\n",
    "    fc2_i = tf.reshape(fc2_i, [-1] + conv2_shape[1:])\n",
    "    convt1_i = conv2d_transpose(fc2_i,\n",
    "                                output_shape=[batch_size] + conv1_shape[1:],\n",
    "                                kernel_size=[int(2*time_context/3), 1],\n",
    "                                stride=[1, 1],\n",
    "                                padding=\"VALID\",\n",
    "                                data_format=data_format,\n",
    "                                weights_initializer=\"xavier\",\n",
    "                                biases_initializer=[\"constant\", 0.0],\n",
    "                                scope=\"CONVT_1_%d\" % (i+1))\n",
    "    convt1.append(convt1_i)\n",
    "    \n",
    "    # Convolutional transpose layer 2\n",
    "    convt2_i = conv2d_transpose(convt1_i,\n",
    "                                output_shape=[batch_size] + input_shape[1:],\n",
    "                                kernel_size=[1, 30],\n",
    "                                stride=[1, 4],\n",
    "                                padding=\"VALID\",\n",
    "                                data_format=data_format,\n",
    "                                weights_initializer=\"xavier\",\n",
    "                                biases_initializer=[\"constant\", 0.0],\n",
    "                                scope=\"CONVT_2_%d\" % (i+1))\n",
    "    convt2.append(convt2_i)\n",
    "\n",
    "# Output layer\n",
    "with tf.name_scope(\"y_hat\"):\n",
    "    convt2_all = tf.concat(convt2, axis=channel_dim)\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[1, 1, 1, 1]),\n",
    "                    dtype=tf.float32,\n",
    "                    name=\"bias\")\n",
    "    y_hat = tf.maximum(tf.add(convt2_all, b), 0, name=\"y_hat\")\n",
    "\n",
    "# Masks: m_n(f) = |y_hat_n(f)| / Σ(|y_hat_n'(f)|)\n",
    "with tf.name_scope(\"masks\"):\n",
    "    rand = tf.random_uniform([batch_size] + input_shape[1:])\n",
    "    den = tf.reduce_sum(y_hat, axis=channel_dim, keep_dims=True) + (eps * rand)\n",
    "    masks = tf.div(y_hat, den, name=\"masks\") # broadcast along channel dimension\n",
    "    \n",
    "# Source signals: y_tilde_n(f) = m_n(f) * x(f), \n",
    "# where x(f) is the spectrogram of the input mixture signal\n",
    "with tf.name_scope(\"y_tilde\"):\n",
    "    y_tilde = tf.multiply(masks, spectrogram, name=\"y_tilde\") # broadcast along channel dimension\n",
    "\n",
    "# Loss function: L = Σ(||y_tilde_n - target_n||^2)\n",
    "with tf.name_scope(\"loss\"):\n",
    "    targets = tf.placeholder(tf.float32, \n",
    "                             shape=target_shape, \n",
    "                             name=\"target_sources\")\n",
    "    reduc_indices = [i for i in range(4) if i != channel_dim]\n",
    "    loss_n = tf.reduce_sum(tf.square(y_tilde - targets), axis=reduc_indices, name=\"loss_n\")\n",
    "    loss_total = tf.reduce_sum(loss_n, name=\"loss_total\")\n",
    "\n",
    "# Optimizer\n",
    "with tf.name_scope(\"train_step\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss_total)\n",
    "\n",
    "# Summaries\n",
    "saver = tf.train.Saver(max_to_keep=5)        \n",
    "graph = tf.get_default_graph()\n",
    "writer = tf.summary.FileWriter(results_dir, graph)\n",
    "loss_sum = []\n",
    "with tf.name_scope(\"summaries\"):\n",
    "    for i in range(num_sources):\n",
    "        loss_sum.append(tf.summary.scalar(\"loss_%d\" % (i+1), loss_n[i]))\n",
    "    loss_sum.append(tf.summary.scalar(\"loss_total\", loss_total))\n",
    "    loss_sum = tf.summary.merge(loss_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
